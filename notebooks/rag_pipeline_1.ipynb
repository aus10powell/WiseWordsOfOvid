{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG Pipeline\n",
    "\n",
    "[Reference RAG Link](https://docs.llamaindex.ai/en/latest/examples/retrievers/auto_merging_retriever.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import utils\n",
    "import configparser\n",
    "from pprint import pprint\n",
    "\n",
    "# Read the INI file\n",
    "config = configparser.RawConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "# Access values from the sections\n",
    "openai_api_section = config[\"OpenAI\"]\n",
    "\n",
    "OPENAI_API_KEY =openai_api_section[\"openai_key\"] \n",
    "\n",
    "import os\n",
    "import openai\n",
    "# openai.api_key = OPENAI_API_KEY#utils.get_openai_api_key()\n",
    "# openai.api_key\n",
    "import utils\n",
    "openai.api_key = utils.get_openai_api_key()\n",
    "import jupyter_black\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of The Amores; or, Amours\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: The Amores; or, Amours\n",
      "\n",
      "\n",
      "Author: Ovid\n",
      "\n",
      "Translator: Henry T. Riley\n",
      "\n",
      "Release date: December 16, 2014 [eBook #47676]\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Produced by David Widger from page images generously\n",
      "        provided by the Internet Archive\n",
      "\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK THE AMORES; OR, AMOURS ***\n",
      "\n",
      "\n",
      "\n",
      "Produced by David Widger from page images generously\n",
      "provided by the Internet Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE AMORES;\n",
      "\n",
      "or, AMOURS\n",
      "\n",
      "\n",
      "By Ovid\n",
      "\n",
      "\n",
      "Literally Translated into English Prose, with Copious Notes, by Henry T. Riley\n",
      "\n",
      "1885\n",
      "\n",
      "\n",
      "BOOK THE FIRST.\n",
      "\n",
      "AN EPIGRAM ON THE AMOURS.\n",
      "\n",
      "|We who of late were five books [001] of Naso, are now but three: this\n",
      "work our author has preferred to the former one. Though it should [002]\n",
      "now be no pleasure to thee to read us; still, the labour will be less,\n",
      "the two being removed.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ELEGY I.\n",
      "\n",
      "_He says that he is compelled by Cupid to write of love instead of\n",
      "battles and that the Divinity insists on making each second Hexameter\n",
      "line into a Pentameter._\n",
      "\n",
      "|I was preparing to write of arms and impetuous warfare in serious\n",
      "numbers, [003] the subject-matter being suited to the measure. [004] The\n",
      "second verse was of equal measure with the first; but Cupid is said to\n",
      "have smiled, and to have abstracted one foot. [005] \"Who, cruel boy,\n",
      "has given thee this right over my lines? We poets are the choir of _the\n",
      "Muses,_ the Pierian maids, not thine. What if Venus were to seize the\n",
      "arms of the yellow-haired Minerva, _and_ if the yellow-haired Minerva\n",
      "were to wave the lighted torches _of Love?_ Who would approve of Ceres\n",
      "holding her reign in the woods on the mountain ridges, _or_ of the\n",
      "fields being tilled under the control of the quivered Virgin? Who would\n",
      "arm Phoebus, graceful with his locks, with the sharp spear, while Mars\n",
      "is striking the Aonian lyre? Thy sway, O youth, is great, and far too\n",
      "potent; why, in thy ambition, dost thou attempt a new task? Is that\n",
      "which is everywhere, thine? Is Heliconian Tempe thine? Is even his own\n",
      "lyre hardly safe now for Phoebus? When the new page has made a good\n",
      "beginning in the first line, at that moment does he diminish my\n",
      "energies. [008] I have no subject fitted for _these_ lighter numbers,\n",
      "whether youth, or girl with her flowing locks arranged.\"\n",
      "\n",
      "_Thus_ was I complaining; when, at once, his quiver loosened, [009] he\n",
      "selected the arrows made for my destruction; and he stoutly bent upon\n",
      "his knee the curving bow, and said, \"Poet, receive a subject on which to\n",
      "sing.\" Ah wretched me! unerring arrows did that youth possess. I\n",
      "burn; and in my heart, _hitherto_ disengaged, does Love hold sway.\n",
      "_Henceforth_, in six feet [010] let my work commence; in five let it\n",
      "close. Farewell, ye ruthless wars, together with your numbers. My Muse,\n",
      "[011] to eleven feet destined to be attuned, bind with the myrtle of the\n",
      "sea shore thy temples encircled with their yellow _locks_.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!curl https://www.gutenberg.org/cache/epub/47676/pg47676.txt > ../data/Amours.txt\n",
    "#!ls ./../data\n",
    "!head -100 ../data/Amours.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "f1 = \"./../data/RemediaAmoris.txt\"\n",
    "f2 = \"./../data/METAMORPHOSES.txt\"\n",
    "f3 = \"./../data/Heroides.txt\"\n",
    "f4 = \"./../data/Amours.txt\"\n",
    "f5 = \"./../data/Fasti.txt\"\n",
    "documents = SimpleDirectoryReader(input_files=[f1, f2, f3, f4, f5]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "5 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: b7e98ad7-02fe-41a4-9821-287e55abe1fc\n",
      "Text: ï»¿The Project Gutenberg eBook of Remedia Amoris; or, The Remedy\n",
      "of Love      This ebook is for the use of anyone anywhere in the\n",
      "United States and most other parts of the world at no cost and with\n",
      "almost no restrictions whatsoever. You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this ebook...\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document], service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment: Sanity-check response\n",
    "# response = query_engine.query(\n",
    "#     \"Who is Aglauros?\"\n",
    "# )\n",
    "# pprint(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"Who is Aglauros?\",\n",
    "    \"What does Thebes want?\",\n",
    "    \"What is the BÅ“otian city?\",\n",
    "    \"What is the context of the quote: 'Resist beginnings; the remedy comes too late when'?\",\n",
    "    \"Who said: They bear punishment with equanimity who have earned it.\",\n",
    "    \"Please explain what this means: They bear punishment with equanimity who have earned it.\"\n",
    "    \"Find a quote similar to the following: 'Resist beginnings; the remedy comes too late when'?\",\n",
    "    \"Who said: 'We're slow to believe what wounds us.'\",\n",
    "    \"Who is The Queen of Erebus?\",\n",
    "    \"Where is the Who is The Queen of Erebus mentioned?\",\n",
    "]\n",
    "# You can try your own question:\n",
    "new_question = \"Who said: No one ought to be pronounced happy before his death, and his last obsequies.?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback, TruLlama, OpenAI\n",
    "\n",
    "# OpenAI(api_key=OPENAI_API_KEY)\n",
    "# help(OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine, app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_0e3c6b387c6b968103837d4d1e87ef62</td>\n",
       "      <td>\"Who is Aglauros?\"</td>\n",
       "      <td>\"Aglauros is a character mentioned in the cont...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_0e3c6b387c6b9681038...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T08:08:57.745957\", \"...</td>\n",
       "      <td>2023-12-02T08:08:59.649741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'Who is Aglauros?', 'resp...</td>\n",
       "      <td>[{'args': {'source': '[Footnote 79: _Plains of...</td>\n",
       "      <td>[{'args': {'prompt': 'Who is Aglauros?', 'resp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2027</td>\n",
       "      <td>0.003046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_af04a180cc54921419b6bc69febe5f84</td>\n",
       "      <td>\"What does Thebes want?\"</td>\n",
       "      <td>\"Thebes wants to regain its honor and expel it...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_af04a180cc54921419b...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T08:08:59.753115\", \"...</td>\n",
       "      <td>2023-12-02T08:09:01.514673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'What does Thebes want?',...</td>\n",
       "      <td>[{'args': {'source': 'Do be mindful, I entreat...</td>\n",
       "      <td>[{'args': {'prompt': 'What does Thebes want?',...</td>\n",
       "      <td>1</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_2ed9819abf9a1484a8307421ce340353</td>\n",
       "      <td>\"What is the B\\u0153otian city?\"</td>\n",
       "      <td>\"The B\\u0153otian city mentioned in the contex...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_2ed9819abf9a1484a83...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T08:09:01.587091\", \"...</td>\n",
       "      <td>2023-12-02T08:09:03.150352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is the BÅ“otian city...</td>\n",
       "      <td>[{'args': {'source': '[Footnote 12: _A mournfu...</td>\n",
       "      <td>[{'args': {'prompt': 'What is the BÅ“otian city...</td>\n",
       "      <td>1</td>\n",
       "      <td>1749</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_1099f02b8c3aa37134dee738474d6815</td>\n",
       "      <td>\"What is the context of the quote: 'Resist beg...</td>\n",
       "      <td>\"The context of the quote \\\"Resist beginnings;...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_1099f02b8c3aa37134d...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T08:09:03.224422\", \"...</td>\n",
       "      <td>2023-12-02T08:09:10.260443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'What is the context of t...</td>\n",
       "      <td>[{'args': {'source': 'For\n",
       "time supplies streng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2167</td>\n",
       "      <td>0.003292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_fd80c6e0541c45a67c6f80daa93a3dcf</td>\n",
       "      <td>\"Who said: They bear punishment with equanimit...</td>\n",
       "      <td>\"Dionysius said: \\\"They bear punishment with e...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_fd80c6e0541c45a67c6...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T08:09:10.334914\", \"...</td>\n",
       "      <td>2023-12-02T08:09:11.849733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'Who said: They bear puni...</td>\n",
       "      <td>[{'args': {'source': 'Krebs, has, I think, she...</td>\n",
       "      <td>[{'args': {'prompt': 'Who said: They bear puni...</td>\n",
       "      <td>1</td>\n",
       "      <td>2068</td>\n",
       "      <td>0.003111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "1  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "2  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "3  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "4  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_0e3c6b387c6b968103837d4d1e87ef62   \n",
       "1  record_hash_af04a180cc54921419b6bc69febe5f84   \n",
       "2  record_hash_2ed9819abf9a1484a8307421ce340353   \n",
       "3  record_hash_1099f02b8c3aa37134dee738474d6815   \n",
       "4  record_hash_fd80c6e0541c45a67c6f80daa93a3dcf   \n",
       "\n",
       "                                               input  \\\n",
       "0                                 \"Who is Aglauros?\"   \n",
       "1                           \"What does Thebes want?\"   \n",
       "2                   \"What is the B\\u0153otian city?\"   \n",
       "3  \"What is the context of the quote: 'Resist beg...   \n",
       "4  \"Who said: They bear punishment with equanimit...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Aglauros is a character mentioned in the cont...    -   \n",
       "1  \"Thebes wants to regain its honor and expel it...    -   \n",
       "2  \"The B\\u0153otian city mentioned in the contex...    -   \n",
       "3  \"The context of the quote \\\"Resist beginnings;...    -   \n",
       "4  \"Dionysius said: \\\"They bear punishment with e...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_0e3c6b387c6b9681038...   \n",
       "1  {\"record_id\": \"record_hash_af04a180cc54921419b...   \n",
       "2  {\"record_id\": \"record_hash_2ed9819abf9a1484a83...   \n",
       "3  {\"record_id\": \"record_hash_1099f02b8c3aa37134d...   \n",
       "4  {\"record_id\": \"record_hash_fd80c6e0541c45a67c6...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2023-12-02T08:08:57.745957\", \"...   \n",
       "1  {\"start_time\": \"2023-12-02T08:08:59.753115\", \"...   \n",
       "2  {\"start_time\": \"2023-12-02T08:09:01.587091\", \"...   \n",
       "3  {\"start_time\": \"2023-12-02T08:09:03.224422\", \"...   \n",
       "4  {\"start_time\": \"2023-12-02T08:09:10.334914\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Groundedness  \\\n",
       "0  2023-12-02T08:08:59.649741               1.0           1.0   \n",
       "1  2023-12-02T08:09:01.514673               1.0           1.0   \n",
       "2  2023-12-02T08:09:03.150352               1.0           1.0   \n",
       "3  2023-12-02T08:09:10.260443               1.0           1.0   \n",
       "4  2023-12-02T08:09:11.849733               1.0           0.0   \n",
       "\n",
       "   Context Relevance                             Answer Relevance_calls  \\\n",
       "0                0.0  [{'args': {'prompt': 'Who is Aglauros?', 'resp...   \n",
       "1                0.0  [{'args': {'prompt': 'What does Thebes want?',...   \n",
       "2                0.0  [{'args': {'prompt': 'What is the BÅ“otian city...   \n",
       "3                NaN  [{'args': {'prompt': 'What is the context of t...   \n",
       "4                0.0  [{'args': {'prompt': 'Who said: They bear puni...   \n",
       "\n",
       "                                  Groundedness_calls  \\\n",
       "0  [{'args': {'source': '[Footnote 79: _Plains of...   \n",
       "1  [{'args': {'source': 'Do be mindful, I entreat...   \n",
       "2  [{'args': {'source': '[Footnote 12: _A mournfu...   \n",
       "3  [{'args': {'source': 'For\n",
       "time supplies streng...   \n",
       "4  [{'args': {'source': 'Krebs, has, I think, she...   \n",
       "\n",
       "                             Context Relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'Who is Aglauros?', 'resp...        1          2027   \n",
       "1  [{'args': {'prompt': 'What does Thebes want?',...        1          2058   \n",
       "2  [{'args': {'prompt': 'What is the BÅ“otian city...        1          1749   \n",
       "3                                                NaN        7          2167   \n",
       "4  [{'args': {'prompt': 'Who said: They bear puni...        1          2068   \n",
       "\n",
       "   total_cost  \n",
       "0    0.003046  \n",
       "1    0.003095  \n",
       "2    0.002632  \n",
       "3    0.003292  \n",
       "4    0.003111  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Who is Aglauros?\"\n",
      "\n",
      "\"Aglauros is a character mentioned in the context.\"\n",
      "\n",
      "\n",
      "\"What does Thebes want?\"\n",
      "\n",
      "\"Thebes wants to regain its honor and expel its feeble foe.\"\n",
      "\n",
      "\n",
      "\"What is the B\\u0153otian city?\"\n",
      "\n",
      "\"The B\\u0153otian city mentioned in the context is Aganippe.\"\n",
      "\n",
      "\n",
      "\"What is the context of the quote: 'Resist beginnings; the remedy comes too late when'?\"\n",
      "\n",
      "\"The context of the quote \\\"Resist beginnings; the remedy comes too late when\\\" is about the importance of taking action and resisting the initial stages of a passion or desire. It emphasizes that if one hesitates for too long, the problem or malady will become stronger and more difficult to cure. The quote encourages individuals to be proactive and not postpone addressing issues, as delaying action will only make the situation worse.\"\n",
      "\n",
      "\n",
      "\"Who said: They bear punishment with equanimity who have earned it.\"\n",
      "\n",
      "\"Dionysius said: \\\"They bear punishment with equanimity who have earned it.\\\"\"\n",
      "\n",
      "\n",
      "\"Please explain what this means: They bear punishment with equanimity who have earned it.Find a quote similar to the following: 'Resist beginnings; the remedy comes too late when'?\"\n",
      "\n",
      "\"\\\"Resist beginnings; the remedy comes too late when\\\" is a quote that emphasizes the importance of preventing a problem or negative situation from occurring in the first place. It suggests that taking action early on is crucial because once a situation has escalated or consequences have been earned, it becomes much more difficult to rectify or mitigate the damage. This quote highlights the significance of being proactive and addressing issues before they become more severe or irreversible.\"\n",
      "\n",
      "\n",
      "\"Who said: 'We're slow to believe what wounds us.'\"\n",
      "\n",
      "\"The speaker who said \\\"We're slow to believe what wounds us\\\" is not mentioned in the given context information.\"\n",
      "\n",
      "\n",
      "\"Who said: No one ought to be pronounced happy before his death, and his last obsequies.?\"\n",
      "\n",
      "\"Nemesis said: \\\"No one ought to be pronounced happy before his death, and his last obsequies.\\\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in records.iterrows():\n",
    "    print(row[\"input\"])\n",
    "    print()\n",
    "    print(row[\"output\"])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32be922679974799a3bac3b24d5e40b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.62:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced RAG Pipeline\n",
    "### 1. Sentence Window Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aglauros is a character who is approached by Mercury in order to gain access to her sister, Herse. She refuses to help him unless he promises to give her a large sum of money.\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\"Who is Aglauros?\")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine, app_id=\"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Aglauros?\n",
      "Aglauros is a character who refuses to assist Mercury in his pursuit of Herse, unless he promises to give her a large sum of money.\n",
      "\n",
      "\n",
      "\n",
      "What does Thebes want?\n",
      "Thebes wants the Theban ladies to go.\n",
      "\n",
      "\n",
      "\n",
      "What is the BÅ“otian city?\n",
      "The BÅ“otian city is not mentioned in the given context information.\n",
      "\n",
      "\n",
      "\n",
      "What is the context of the quote: 'Resist beginnings; the remedy comes too late when'?\n",
      "The context of the quote \"Resist beginnings; the remedy comes too late when\" cannot be determined based on the provided information.\n",
      "\n",
      "\n",
      "\n",
      "Who said: They bear punishment with equanimity who have earned it.\n",
      "The speaker who said, \"They bear punishment with equanimity who have earned it,\" is not mentioned in the given context information.\n",
      "\n",
      "\n",
      "\n",
      "Please explain what this means: They bear punishment with equanimity who have earned it.Find a quote similar to the following: 'Resist beginnings; the remedy comes too late when'?\n",
      "They bear punishment with equanimity who have earned it means that those who have done something wrong and deserve to be punished accept their punishment calmly and without complaint. It implies that they acknowledge their wrongdoing and understand that they must face the consequences.\n",
      "\n",
      "A similar quote to 'Resist beginnings; the remedy comes too late when' could be \"Prevention is better than cure.\"\n",
      "\n",
      "\n",
      "\n",
      "Who said: 'We're slow to believe what wounds us.'\n",
      "There is no information provided in the given context about who said the phrase \"We're slow to believe what wounds us.\" Therefore, it is not possible to determine who said this statement based on the given context information.\n",
      "\n",
      "\n",
      "\n",
      "Who is The Queen of Erebus?\n",
      "The Queen of Erebus is Semele.\n",
      "\n",
      "\n",
      "\n",
      "Where is the Who is The Queen of Erebus mentioned?\n",
      "The Queen of Erebus is mentioned in the given context.\n",
      "\n",
      "\n",
      "\n",
      "Who said: No one ought to be pronounced happy before his death, and his last obsequies.?\n",
      "Solon\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Context Relevance  \\\n",
       "app_id                                                              \n",
       "Sentence Window Query Engine              0.75                0.0   \n",
       "\n",
       "                              Groundedness  latency  total_cost  \n",
       "app_id                                                           \n",
       "Sentence Window Query Engine           0.0      2.1    0.000735  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.4.62:8501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Auto-Merging Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"merging_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_automerging_query_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Queen of Erebus is Persephone.\n"
     ]
    }
   ],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\"Who is The Queen of Erebus?\")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(\n",
    "    automerging_query_engine, app_id=\"Automerging Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function BaseQueryEngine.query at 0x137ea2200>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.retrievers.auto_merging_retriever.AutoMergingRetriever'> at 0x297a18850 is calling an instrumented method <function BaseRetriever.retrieve at 0x137ea15a0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app.retriever based on other object (0x40a56d000) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x3da794c10 is calling an instrumented method <function BaseRetriever.retrieve at 0x137ea15a0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app.retriever based on other object (0x40a56d000) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: ccae6d21-c328-408d-ae97-92083798eebe.\n",
      "> Parent node text: Hyginus also speaks of her as being\n",
      "    the daughter of Oceanus. From the name â€˜Nysa,â€™ Bacchus re...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function CompactAndRefine.get_response at 0x164c3a680>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.llm_predictor.base.LLMPredictor'> at 0x471d78280 is calling an instrumented method <function LLMPredictor.predict at 0x122fd2440>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer.service_context.llm_predictor based on other object (0x30005b6c0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Aglauros?\n",
      "Aglauros is a character mentioned in the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does Thebes want?\n",
      "Thebes wants an unarmed boy to take over the city.\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 8a72d278-21cd-4835-b1e9-d992f7d63744.\n",
      "> Parent node text: 228. This and Amphrysus were\n",
      "    rivers of Thessaly.]\n",
      "\n",
      "    [Footnote 27: _Shores of BÅ“be._--Ver. ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the BÅ“otian city?\n",
      "The BÅ“otian city is a city that was instructed to be built by someone under the guidance of a certain individual.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the context of the quote: 'Resist beginnings; the remedy comes too late when'?\n",
      "The context of the quote \"Resist beginnings; the remedy comes too late when\" cannot be determined based on the provided context information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who said: They bear punishment with equanimity who have earned it.\n",
      "Pentheus said: They bear punishment with equanimity who have earned it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please explain what this means: They bear punishment with equanimity who have earned it.Find a quote similar to the following: 'Resist beginnings; the remedy comes too late when'?\n",
      "Those who have earned punishment bear it with equanimity. It means that when someone has done something to deserve punishment, they accept it calmly and without complaint. They understand that they are responsible for their actions and are willing to face the consequences. \n",
      "\n",
      "A quote similar to \"Resist beginnings; the remedy comes too late when\" could be \"Prevention is better than cure.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n",
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x44feb5a80 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1760313f0>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x3da7a1f60) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who said: 'We're slow to believe what wounds us.'\n",
      "The speaker who said, \"We're slow to believe what wounds us,\" is not mentioned in the given context information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x44feb4a00 is calling an instrumented method <function Refine.get_response at 0x1651cd990>. The path of this call may be incorrect.\n",
      "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x40a56e7d0) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who said: No one ought to be pronounced happy before his death, and his last obsequies.?\n",
      "Solon said: No one ought to be pronounced happy before his death, and his last obsequies.\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automerging Query Engine</th>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Answer Relevance  Context Relevance  Groundedness  \\\n",
       "app_id                                                                        \n",
       "Automerging Query Engine            0.6125                0.2           0.5   \n",
       "\n",
       "                          latency  total_cost  \n",
       "app_id                                         \n",
       "Automerging Query Engine      2.5    0.000549  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.4.62:8501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
