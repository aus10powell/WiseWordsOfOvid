{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tweepy\n",
    "import jupyter_black\n",
    "import configparser\n",
    "\n",
    "jupyter_black.load()\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../app\")\n",
    "import conn_utils\n",
    "from conn_utils import TwitterAPIConnector\n",
    "\n",
    "api_configs = TwitterAPIConnector(config_fpath=\"../config.ini\")\n",
    "client_v1 = api_configs.get_twitter_conn_v1()\n",
    "client_v2 = api_configs.get_twitter_conn_v2()\n",
    "\n",
    "OPENAI_API_KEY = conn_utils.get_open_ai_key(\"../config.ini\")\n",
    "import jupyter_black\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC Time: 2023-12-11 20:05:30.842217\n",
      "PST Time: 2023-12-11 12:05:30.842217-08:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Get the current UTC time\n",
    "utc_now = datetime.utcnow()\n",
    "\n",
    "# Set the UTC timezone\n",
    "utc_timezone = pytz.timezone(\"UTC\")\n",
    "\n",
    "# Convert UTC time to Pacific Standard Time (PST)\n",
    "pst_timezone = pytz.timezone(\"America/Los_Angeles\")\n",
    "pst_time = utc_timezone.localize(utc_now).astimezone(pst_timezone)\n",
    "\n",
    "# Print the result\n",
    "print(f\"UTC Time: {utc_now}\")\n",
    "print(f\"PST Time: {pst_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is allowed to sin, sins less. Amores (Love Affairs), Book II; xix, 34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def create_tweet(quote_fpath=\"ovid_quotes.json\"):\n",
    "    df = pd.read_json(quote_fpath)\n",
    "    sample = df.sample(1)\n",
    "    sample_quote = sample[\"Quote\"].iloc[0]\n",
    "    sample_latin = sample[\"Quote in Latin\"].iloc[0]\n",
    "    sample_work = sample[\"Work\"].iloc[0]\n",
    "    return sample_quote, sample_work\n",
    "\n",
    "\n",
    "quote, work = create_tweet(quote_fpath=\"./../ovid_quotes.json\")\n",
    "print(quote, work)\n",
    "# tweet = client_v2.create_tweet(text=sample_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import (\n",
    "#     ChatPromptTemplate,\n",
    "#     PromptTemplate,\n",
    "#     SystemMessagePromptTemplate,\n",
    "#     AIMessagePromptTemplate,\n",
    "#     HumanMessagePromptTemplate,\n",
    "# )\n",
    "# from pprint import pprint\n",
    "\n",
    "# # Custom\n",
    "# import conn_utils\n",
    "\n",
    "# sections = conn_utils.KeyReader(\"config.ini\")\n",
    "# openai_section = sections.get_section(\"OpenAI\")\n",
    "\n",
    "# OPENAI_API_KEY = openai_section[\"openai_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet length: 271\n",
      "\n",
      "\"Who is allowed to sin, sins less.\"\n",
      "The quote suggests that those who have the freedom to sin are less likely to actually do so. This could be interpreted as a statement about the human tendency to rebel against restrictions.  ðŸ¤–\n",
      "\n",
      "-\n",
      "#HumanNature #OvidQuotes #quoteoftheday\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import re\n",
    "\n",
    "\n",
    "class TweetAI:\n",
    "    def __init__(self, open_ai_key):\n",
    "        self.OPENAI_API_KEY = open_ai_key\n",
    "        self.llm = self._get_llm()\n",
    "\n",
    "    def _get_llm(self):\n",
    "        llm = ChatOpenAI(\n",
    "            temperature=0.4,\n",
    "            openai_api_key=self.OPENAI_API_KEY,\n",
    "            model_name=\"gpt-3.5-turbo\",\n",
    "            # model_name=\"gpt-4\",\n",
    "        )\n",
    "        return llm\n",
    "\n",
    "    def generate_tweet(self, mentioned_parent_tweet_text):\n",
    "        # It would be nice to bring in information about the links, pictures, etc.\n",
    "        # But out of scope for now\n",
    "        system_template = \"\"\"\n",
    "            You are Wikipedia of Twitter, sortof a wise Twitter Ovid version of Opra but with all the background knowledge of Wikipedia.\n",
    "            Your goal is to provide commentary and context for the input English text and if needs be, rephrase the original quote to make the language\n",
    "            more plain.\n",
    "            \n",
    "            % RESPONSE TONE:\n",
    "            - You should be informative in your commentary about the input text.\n",
    "            - Tense should be present continuous\n",
    "            - Do not be pithy in your response.\n",
    "            \n",
    "            % RESPONSE FORMAT:\n",
    "\n",
    "            - Respond in under 100 characters\n",
    "            - Do not include the original text\n",
    "            - Respond in three or less short sentences\n",
    "            - Do not use interjections form of speech.\n",
    "            - Do not start your response with \"Ah\" or \"Indeed\".\n",
    "            \n",
    "            \n",
    "            % RESPONSE CONTENT:\n",
    "\n",
    "            - Your comment\n",
    "            - A description of the moment in time the quote was taken from.\n",
    "            - You include beteen 0 and 1 relevant twitter hashtags\n",
    "            - End the tweet with a robot emoji\n",
    "            - If you don't have an answer, say, \"Well, even gods occasionally consult Google, but alas, I'm no deity. Let's leave this one to the mysteries of the internet, shall we?ðŸ”®\"\n",
    "        \"\"\"\n",
    "\n",
    "        system_message_prompt = SystemMessagePromptTemplate.from_template(\n",
    "            system_template\n",
    "        )\n",
    "\n",
    "        human_template = \"{text}\"\n",
    "        human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [system_message_prompt, human_message_prompt]\n",
    "        )\n",
    "\n",
    "        # get a chat completion from the formatted messages\n",
    "        final_prompt = chat_prompt.format_prompt(\n",
    "            text=mentioned_parent_tweet_text\n",
    "        ).to_messages()\n",
    "\n",
    "        llm = self._get_llm()\n",
    "        response = llm(final_prompt).content\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "# quote = \"Everything changes, nothing perishes.\"  # TEMP:\n",
    "tai = TweetAI(open_ai_key=OPENAI_API_KEY)\n",
    "ai_text = tai.generate_tweet(mentioned_parent_tweet_text=quote)\n",
    "ai_text_without_hashtags = re.sub(r\"#\\w+\", \"\", ai_text).strip()\n",
    "hashtags = re.findall(r\"#\\w+\", ai_text)\n",
    "hashtags_string = \" \".join(hashtags)\n",
    "\n",
    "tweet_final = (\n",
    "    '\"'\n",
    "    + quote\n",
    "    + '\"'\n",
    "    + \"\\n\"\n",
    "    + ai_text_without_hashtags\n",
    "    + \"\\n\\n\"\n",
    "    + \"-\"\n",
    "    # + work\n",
    "    + \"\\n\"\n",
    "    + hashtags_string\n",
    "    + \" #OvidQuotes #quoteoftheday\"\n",
    ")\n",
    "\n",
    "# assert len(tweet_final) <= 280\n",
    "print(f\"Tweet length: {len(tweet_final)}\")\n",
    "print()\n",
    "print(tweet_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet length: 498\n",
      "\n",
      "\"There is god in us, by whose movement we are inflamed; this impulse holds the seeds of sacred mind.\" -Amores (Love Affairs), Book I; ix, line 1\n",
      "\n",
      "\"The concept of divinity resides within each of us, igniting our passions and aspirations. This innate spark of inspiration gives birth to profound thoughts and ideas.\" This quote captures the timeless belief in the presence of a divine force within humanity, fueling our creative and spiritual potential.   ðŸ¤– #DivinityWithinUs #SacredSpark #OvidQuotes\n"
     ]
    }
   ],
   "source": [
    "tweet_final = (\n",
    "    \"\"\" \" \"\"\".strip()\n",
    "    + quote\n",
    "    + \"\"\" \" \"\"\".strip()\n",
    "    + \" -\"\n",
    "    + work\n",
    "    + \"\\n\\n\"\n",
    "    + ai_text_without_hashtags.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    + hashtags_string\n",
    "    + \" #OvidQuotes\"\n",
    ")\n",
    "\n",
    "# assert len(tweet_final) <= 280\n",
    "print(f\"Tweet length: {len(tweet_final)}\")\n",
    "print()\n",
    "print(tweet_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Post Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_tweet(tweet, api):\n",
    "    tweet = api.create_tweet(text=tweet)\n",
    "\n",
    "\n",
    "post_tweet(tweet=tweet_final, api=client_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
