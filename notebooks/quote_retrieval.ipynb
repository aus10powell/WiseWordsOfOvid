{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quote Generation/Retrieval\n",
    "\n",
    "Initial quotes were scraped from one webpage. But that would lead to quite a lot of repitition and kindof a boring bot. So...\n",
    "\n",
    "### 2 Issues with Index retrieved/Generated Quotes:\n",
    "**Goal:** To have ~100 quotes to have tweeted on a rolling basis since this is a quarter of a year and will not likely to be easily repeated.\n",
    "\n",
    "### Probability of Repeating a Quote Exactly 2 Weeks Later\n",
    "\n",
    "\\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) = 1 - \\left( \\frac{N - 1}{N} \\right)^{\\frac{14}{m}}\n",
    "\\end{equation*}\n",
    "\n",
    " Substituting in the values:\n",
    "\n",
    " \\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) = 1 - \\left( \\frac{99}{100} \\right)^{14}\n",
    "\\end{equation*}\n",
    "\n",
    " Calculating this gives:\n",
    "\n",
    " \\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) \\approx 0.135\n",
    "\\end{equation*}\n",
    "\n",
    "Personally, I'd like it to be under 10% for a longer period of time (increases probability)\n",
    "\n",
    "Tweaking the numbers a bit \n",
    "N = 200\n",
    "days = 21\n",
    "\n",
    "\\begin{equation*}\n",
    "P(\\text{repeated in 3 weeks}) \\approx  0.0980\n",
    "\\end{equation*}\n",
    "\n",
    "The following should be conditional 1) That the quote generated has confidence that the quote was written by Ovid then 2) That the quote is not a variation of a quote already in DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# import utils\n",
    "import configparser\n",
    "from pprint import pprint\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()\n",
    "# Access values from the sections\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../app\")\n",
    "import conn_utils\n",
    "\n",
    "OPENAI_API_KEY = conn_utils.get_open_ai_key(\"./../app/config.ini\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "directory = \"index_store\"\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmoresV2.txt                    MetamorphosesV2.txt\n",
      "ArsAmatoria.txt                 PoemsFromExile.txt\n",
      "FastiV2.txt                     RemediaAmorisV2.txt\n",
      "HeroidesV2.txt                  TheOdesofHorace_10227561(3).txt\n",
      "LostPoemsV2.txt                 notes.jsonl\n",
      "LoversAssistant.txt             notes_validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get low sentency similarity\n",
    "\n",
    "Instead of using a LLM. You can trust to get a close (but not too close) similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sentences: 6897\n",
      "['Ovid: The Poems Of Exile \\n'\n",
      " '(Tristia, Ex Ponto, Ibis) \\n'\n",
      " ' \\n'\n",
      " 'Home\\n'\n",
      " 'Download\\n'\n",
      " '2\\n'\n",
      " 'Translated by A. S. Kline \\uf8e92003\\n'\n",
      " 'All Rights Reserved \\n'\n",
      " 'This work may be freely \\n'\n",
      " 'reproduced, stored, and \\n'\n",
      " 'transmitted, electronically or \\n'\n",
      " 'otherwise, for any non-commercial \\n'\n",
      " 'purpose. \\n'\n",
      " ' \\n',\n",
      " '3\\n'\n",
      " 'Contents\\n'\n",
      " 'Tristia Book '\n",
      " 'I.................................................................. 11 \\n'\n",
      " 'Book TI.I:1-68 The Poet to His Book: Its Nature ........... 11 \\n'\n",
      " 'Book TI.I:70-128 The Poet to His Book: His Works...... 14 \\n'\n",
      " 'Book TI.II:1-74 The Journey: Storm at Sea.................... 17 \\n'\n",
      " 'Book TI.II:75-110 The Journey: The Destination........... 21 \\n'\n",
      " 'Book TI.III:1-46 The Final Night in Rome:',\n",
      " 'Preparation 23 \\nBook TI.III:47-102 The Final Night in Rome: Departure25 \\n',\n",
      " 'Book TI.IV:1-28 Troubled Waters.................................. 28 \\n'\n",
      " 'Book TI.V:1-44 Loyalty in Friendship ...........................',\n",
      " '30 \\nBook TI.V:45-84']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Read in exisitng quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Define the file paths\n",
    "f1 = \"./../data/FastiV2.txt\"\n",
    "f2 = \"./../data/MetamorphosesV2.txt\"\n",
    "f3 = \"./../data/AmoresV2.txt\"\n",
    "f4 = \"./../data/LostPoemsV2.txt\"\n",
    "f5 = \"./../data/HeroidesV2.txt\"\n",
    "f6 = \"./../data/ArsAmatoria.txt\"\n",
    "f7 = \"./../data/RemediaAmorisV2.txt\"\n",
    "f8 = \"./../data/LoversAssistant.txt\"\n",
    "\n",
    "# Read in the text files and split sentences\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Override the max length of the text\n",
    "nlp.max_length = 1500000  # or any value that accommodates your text length\n",
    "\n",
    "with open(os.path.join(\"./../data\", \"LostPoemsV2.txt\"), \"r\") as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "sentences = [sent.text for sent in doc.sents]\n",
    "# Print the list of sentences\n",
    "print(f\"Num sentences: {len(sentences)}\")\n",
    "pprint(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "\n",
    "#df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "# ## Update add new quotes to the dataframe\n",
    "# new_row = {\n",
    "#     \"Quote\": \"\"\"You will go most safely by the middle way.\"\"\",\n",
    "#     \"Work\": \"Metamorphoses\",\n",
    "#     \"Quote in Latin\": \"\",\n",
    "# }\n",
    "# df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "# df.to_json(\"./../app/ovid_quotes.json\")\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Quote in Latin</th>\n",
       "      <th>Work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We're slow to believe what wounds us.</td>\n",
       "      <td>Tarde quae credita laedunt credimus.</td>\n",
       "      <td>Heroides (The Heroines), II, 9-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>And did you, my hands, seize the horns of the mighty bull?</td>\n",
       "      <td>Tenuistine, manus meae, cornua tauri magni?</td>\n",
       "      <td>Metamorphoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Everything changes, nothing perishes.</td>\n",
       "      <td>None</td>\n",
       "      <td>Metamorphoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”</td>\n",
       "      <td>Exitus acta probat.</td>\n",
       "      <td>Heroides (The Heroines), II, 85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Everything changes, nothing perishes.</td>\n",
       "      <td>Omnia mutantur, nihil interit</td>\n",
       "      <td>- Metamorphoses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                         Quote  \\\n",
       "2                                                                                                                                        We're slow to believe what wounds us.   \n",
       "32                                                                                                                  And did you, my hands, seize the horns of the mighty bull?   \n",
       "23                                                                                                                                       Everything changes, nothing perishes.   \n",
       "3   The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”   \n",
       "18                                                                                                                                       Everything changes, nothing perishes.   \n",
       "\n",
       "                                 Quote in Latin  \\\n",
       "2          Tarde quae credita laedunt credimus.   \n",
       "32  Tenuistine, manus meae, cornua tauri magni?   \n",
       "23                                         None   \n",
       "3                           Exitus acta probat.   \n",
       "18                Omnia mutantur, nihil interit   \n",
       "\n",
       "                                 Work  \n",
       "2   Heroides (The Heroines), II, 9-10  \n",
       "32                      Metamorphoses  \n",
       "23                      Metamorphoses  \n",
       "3     Heroides (The Heroines), II, 85  \n",
       "18                    - Metamorphoses  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13030\n",
      "9547\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_sentences(sentences, filter_tokens):\n",
    "    def replace_non_alphanumeric(input_string):\n",
    "        processed_text = re.sub(r\"\\n\", \" \", input_string)\n",
    "        processed_text = re.sub(r\"[^a-zA-Z0-9\\s.,?!'\\-]\", \" \", processed_text)\n",
    "        return processed_text\n",
    "\n",
    "    def contains_filter_tokens(input_string):\n",
    "        return any(token in input_string for token in filter_tokens)\n",
    "\n",
    "    cleaned_sentences = [s.replace(\"\\n\", \". \").replace(\"_\", \" \") for s in sentences]\n",
    "    cleaned_sentences = [replace_non_alphanumeric(s) for s in sentences]\n",
    "    cleaned_sentences = [s for s in cleaned_sentences if len(s.split()) > 4]\n",
    "    cleaned_sentences = [s for s in cleaned_sentences if not contains_filter_tokens(s)]\n",
    "\n",
    "    return cleaned_sentences\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(len(sentences))\n",
    "filter_tokens = [\n",
    "    \"Project Gutenberg\",\n",
    "    \"Footnote\",\n",
    "    \"--Ver.\",\n",
    "    \"The Amores\",\n",
    "    \"United States\",\n",
    "    \"copyright\",\n",
    "    \"Copyright\",\n",
    "    \"gutenberg\",\n",
    "    \"Gutenberg\",\n",
    "]\n",
    "cleaned = clean_sentences(sentences, filter_tokens)\n",
    "print(len(cleaned))\n",
    "\n",
    "# Uncomment to use the clean sentences\n",
    "sentences = clean_sentences(sentences, filter_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gods delight in instances of such testimony, since they, thereby, give witness of their powers. \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sampled_cell = random.choice(cleaned)\n",
    "print(sampled_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Before:\n",
      "['Why tremble or hesitate to approach her?', 'It’s no impious\\nProcne or Medea who’s to be moved by your words,\\nno murderous Danaid, not Agamemnon’s cruel wife,\\nno yelping Scylla terrorising Sicilian waters,\\nno Circe born with the power to alter forms,\\nno Medusa binding her knotted hair with snakes,\\nbut the first of women, in whom Fortune shows herself\\nas clear-sighted, and falsely charged with being blind:\\nthan whom the earth holds nothing more glorious,\\nsave Caesar, from the sun’s rising to its setting.']\n",
      "\n",
      "Sentences After:\n",
      "['to ask,\\nlest your boat sets sail on an adverse tide.\\n263\\n\\n\\x0cThe oracles don’t always deliver sacred prophecies,\\nthe temples themselves aren’t always open.\\n', 'When the city’s state is as I now divine it,\\nand there’s no grief on peoples’ faces,\\nwhen Augustus’s house, to be revered as the Capitol,\\nis as happy as it is now, and filled with peace,\\nthen may the gods grant you the chance to make an\\napproach,\\nthen reflect your words may achieve something.\\n']\n"
     ]
    }
   ],
   "source": [
    "corpus_text = text\n",
    "# The string you want to find\n",
    "target_string = \"Choose a well-considered time\"\n",
    "\n",
    "# Find the index of the target string\n",
    "start_index = corpus_text.find(target_string)\n",
    "\n",
    "# Ensure the target string is found in the corpus\n",
    "if start_index != -1:\n",
    "    # Extract the text before and after the target string\n",
    "    text_before = corpus_text[:start_index].strip()\n",
    "    text_after = corpus_text[start_index + len(target_string) :].strip()\n",
    "\n",
    "    # Tokenize the sentences using spaCy\n",
    "    doc_before = nlp(text_before)\n",
    "    doc_after = nlp(text_after)\n",
    "\n",
    "    # Get the sentences\n",
    "    sentences_before = [sent.text for sent in doc_before.sents][-2:]\n",
    "    sentences_after = [sent.text for sent in doc_after.sents][:2]\n",
    "\n",
    "    # Print or use the extracted sentences\n",
    "    print(\"Sentences Before:\")\n",
    "    print(sentences_before)\n",
    "\n",
    "    print(\"\\nSentences After:\")\n",
    "    print(sentences_after)\n",
    "else:\n",
    "    print(\"Target string not found in the corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1470/6897 [00:13<00:48, 112.50it/s]/var/folders/qq/gdppvj912kv3ds7_xnf0q_fc0000gn/T/ipykernel_1780/2642853869.py:16: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similarity_score = doc_generated.similarity(doc_actual)\n",
      "100%|██████████| 6897/6897 [00:53<00:00, 130.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Though exile is grief, my offence is more so: \\nand deserving punishment’s worse than suffering it. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.872372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>Fortunate silver, more blessed than any gold, \\nthat was recently coarse metal, is now divine. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.821469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>That too is more than I want.</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.814626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>My current distress is harder than before: though still \\nsimilar in nature, it’s grown and deepened with time. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.814061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>Believe me, what I complain of is less than the truth. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.812927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              new_quotes  \\\n",
       "1572              Though exile is grief, my offence is more so: \\nand deserving punishment’s worse than suffering it. \\n   \n",
       "2116                   Fortunate silver, more blessed than any gold, \\nthat was recently coarse metal, is now divine. \\n   \n",
       "1154                                                                                       That too is more than I want.   \n",
       "1096  My current distress is harder than before: though still \\nsimilar in nature, it’s grown and deepened with time. \\n   \n",
       "1371                                                           Believe me, what I complain of is less than the truth. \\n   \n",
       "\n",
       "                        actual_quotes  similarity_score  \n",
       "1572  Nothing is stronger than habit.          0.872372  \n",
       "2116  Nothing is stronger than habit.          0.821469  \n",
       "1154  Nothing is stronger than habit.          0.814626  \n",
       "1096  Nothing is stronger than habit.          0.814061  \n",
       "1371  Nothing is stronger than habit.          0.812927  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity_data = []\n",
    "\n",
    "# Sample similarity quotes\n",
    "# But I won t refute a thing  I favour your praise too  For, heart, why reject the voice that is desired? Don t be angry if my belief in you comes only with great  difficulty  trust in important things usually builds slowly.\n",
    "\n",
    "\n",
    "quotes = [\"\"\"Nothing is stronger than habit.\"\"\"]\n",
    "for actual_quote in quotes:\n",
    "    doc_actual = nlp(actual_quote)\n",
    "\n",
    "    for sent in tqdm(sentences):\n",
    "        doc_generated = nlp(sent)\n",
    "        # Calculate similarity score\n",
    "        similarity_score = doc_generated.similarity(doc_actual)\n",
    "\n",
    "        # Append data to the list\n",
    "        similarity_data.append(\n",
    "            {\n",
    "                \"new_quotes\": doc_generated.text,\n",
    "                \"actual_quotes\": actual_quote,\n",
    "                \"similarity_score\": similarity_score,\n",
    "            }\n",
    "        )\n",
    "# Create a DataFrame from the similarity data\n",
    "similarity_df = pd.DataFrame(similarity_data).sort_values(\n",
    "    \"similarity_score\", ascending=False\n",
    ")\n",
    "display(similarity_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>Book TII:253-312 Juno drove Io over the sea. \\n \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.377661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>However they were inflicted on me, cease asking \\nabout them: don’t disturb them if you want them to heal. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.532814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>Ovid implies no alms collecting was allowed the \\npriestesses and prophets \\nof the goddess. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.618541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>Or like the Atarnean may you be brought, basely, \\nto your lord as a prize, sewn inside a bull’s-hide. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.684119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>She fell in love with Hippomenes.</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.482530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>The slave girl, singing at her work, spinning the thread, \\ndiverts herself, and whiles away the hours of toil. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.575349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>He’d deny \\nthat loyalty’s only the friend of tranquil times. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.631652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Whatever happened should be called an error, not a crime. \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.697320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>Book TI.VII:1-40 Distant from his friends. \\n \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.311817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>Book EIII.1:1-66 Made more famous by his fate. \\n \\n</td>\n",
       "      <td>Nothing is stronger than habit.</td>\n",
       "      <td>0.380218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              new_quotes  \\\n",
       "4841                                                                  Book TII:253-312 Juno drove Io over the sea. \\n \\n   \n",
       "1766       However they were inflicted on me, cease asking \\nabout them: don’t disturb them if you want them to heal. \\n   \n",
       "4213                     Ovid implies no alms collecting was allowed the \\npriestesses and prophets \\nof the goddess. \\n   \n",
       "3037           Or like the Atarnean may you be brought, basely, \\nto your lord as a prize, sewn inside a bull’s-hide. \\n   \n",
       "3541                                                                                   She fell in love with Hippomenes.   \n",
       "947   The slave girl, singing at her work, spinning the thread, \\ndiverts herself, and whiles away the hours of toil. \\n   \n",
       "2816                                                    He’d deny \\nthat loyalty’s only the friend of tranquil times. \\n   \n",
       "1767                                                        Whatever happened should be called an error, not a crime. \\n   \n",
       "5404                                                                    Book TI.VII:1-40 Distant from his friends. \\n \\n   \n",
       "5921                                                                Book EIII.1:1-66 Made more famous by his fate. \\n \\n   \n",
       "\n",
       "                        actual_quotes  similarity_score  \n",
       "4841  Nothing is stronger than habit.          0.377661  \n",
       "1766  Nothing is stronger than habit.          0.532814  \n",
       "4213  Nothing is stronger than habit.          0.618541  \n",
       "3037  Nothing is stronger than habit.          0.684119  \n",
       "3541  Nothing is stronger than habit.          0.482530  \n",
       "947   Nothing is stronger than habit.          0.575349  \n",
       "2816  Nothing is stronger than habit.          0.631652  \n",
       "1767  Nothing is stronger than habit.          0.697320  \n",
       "5404  Nothing is stronger than habit.          0.311817  \n",
       "5921  Nothing is stronger than habit.          0.380218  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/gdppvj912kv3ds7_xnf0q_fc0000gn/T/ipykernel_36937/2330900647.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_score = doc_generated.similarity(doc_actual)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Let the man who does not wish to be idle fall in love!',\n",
       " 'To love and be loved is to feel the sun from both sides.',\n",
       " \"Love yields to business. If you seek a way out of love, be busy; you'll be safe then.\",\n",
       " 'Happy is the man who has broken the chains which hurt the mind, and has given up worrying once and for all.',\n",
       " 'Nothing is stronger than habit.',\n",
       " 'Dripping water hollows out stone, not through force but through persistence.',\n",
       " 'It is no use to blame the looking glass if your face is awry.',\n",
       " 'Resist beginnings; the remedy comes too late when the disease has gained strength by long delays.',\n",
       " 'The mind, conscious of rectitude, laughed to scorn the falsehood of report.',\n",
       " 'The cause is hidden. The effect is visible to all.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################\n",
    "# POC: To see if generate a response based on a quote\n",
    "# Situation: There is a general tweet\n",
    "# Task: Generate a list of candidate quotes\n",
    "# Action: Create a model that assigns a score to each quote\n",
    "# Result: The top 1 quote is returned\n",
    "##################################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "DATA_DIR = \"./../data\"\n",
    "files = [\n",
    "    \"RemediaAmoris.txt\",\n",
    "    \"Heroides.txt\",\n",
    "    \"Amours.txt\",\n",
    "    \"Fasti.txt\",\n",
    "    \"MetamorphosesI_VII.txt\",\n",
    "    \"MetamorphosesVIII_XV.txt\",\n",
    "    \"MetamorphosesofPublius.txt\",\n",
    "    \"LoversAssistant.txt\",\n",
    "    \"LastPoems.txt\",\n",
    "]\n",
    "docs = [f\"{DATA_DIR}/{file}\" for file in files]\n",
    "documents = SimpleDirectoryReader(input_files=docs).load_data()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=25)\n",
    "texts = text_splitter.create_documents(docs)\n",
    "directory = \"index_store\"\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local(\"index_store\", OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_interface = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "response = qa_interface(\n",
    "    f\"\"\"\n",
    "I am a big fan of ovid. \n",
    "Please recommend 10 memorable quotes to me along with the source document they were taken from.\n",
    "\n",
    "Do NOT include quotes I already have:\n",
    "{df[\"Quote\"].tolist()}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authorship authentication\n",
    "\n",
    "**[Who Wrote it and Why?\n",
    "Prompting Large-Language Models for Authorship Verification](https://arxiv.org/pdf/2310.08123.pdf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Authorship Attribution\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "\n",
    "template = f\"\"\"Task: On a scale of 0 to 1, with 0 indicating low confidence\n",
    "and 1 indicating high confidence, please provide a general\n",
    "assessment of the likelihood that given text \n",
    "written by the same author as the provided reference. Your answer should reflect a\n",
    "moderate level of strictness in scoring. Here are some\n",
    "relevant variables to this problem.\n",
    "1. punctuation style(e.g. hyphen, brackets, colon, comma,\n",
    "parenthesis, quotation mark)\n",
    "2. special characters style, capitalization style(e.g.\n",
    "Continuous capitalization, capitalizing certain words)\n",
    "3. acronyms and abbreviations(e.g. Usage of acronyms\n",
    "such as OMG, Abbreviations without punctuation marks\n",
    "such as Mr Rochester vs. Mr. Rochester,Unusual\n",
    "abbreviations such as def vs. definitely)\n",
    "4. writing style\n",
    "5. expressions and Idioms\n",
    "6. tone and mood\n",
    "7. sentence structure\n",
    "8. any other relevant aspect\n",
    "First step: Understand the problem, extracting relevant\n",
    "variables and devise a plan to solve the problem. Then,\n",
    "carry out the plan and solve the problem step by step.\n",
    "9. One (or both) of the texts is written by the famous Latin author \"Ovid\"\n",
    "Finally, show the confidence score.\n",
    "\n",
    "The following are all quotes by Ovid for reference:\n",
    "'Love is a thing full of anxious fears.',\n",
    " 'Now are fields of corn where Troy once stood.',\n",
    " \"We're slow to believe what wounds us.\",\n",
    " \"The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”\",\n",
    " \"Let him who loves, where love success may find, Spread all his sails before the prosp'rous wind.\",\n",
    " 'Resist beginnings; the remedy comes too late when the disease has gained strength by long delays.',\n",
    " \"Love yields to business. If you seek a way out of love, be busy; you'll be safe then.\",\n",
    " 'The gods behold all righteous actions.',\n",
    " 'There is a god within us.',\n",
    " 'The mind, conscious of rectitude, laughed to scorn the falsehood of report.',\n",
    " 'Every lover is a soldier.',\n",
    " 'Let the man who does not wish to be idle fall in love!',\n",
    " 'Far away be that fate!',\n",
    " 'They bear punishment with equanimity who have earned it.',\n",
    " \"We take no pleasure in permitted joys. But what's forbidden is more keenly sought.\",\n",
    " 'Who is allowed to sin, sins less.' \n",
    " \n",
    " \"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ]\n",
    ")\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Quotes from LLM Authorshipp Attribution\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "input_string = response[\"result\"]\n",
    "\n",
    "\n",
    "def get_quotes(input_string):\n",
    "    \"\"\"Extract quotes from a string that has been created by an LLM string prompt.\"\"\"\n",
    "    # Extract the lines that start with a number\n",
    "    lines_with_stripped_numbers = [\n",
    "        re.sub(r\"^\\d+\\.\\s*\", \"\", line.strip())\n",
    "        for line in input_string.splitlines()\n",
    "        if re.match(r\"^\\d+\\.\", line)\n",
    "    ]\n",
    "\n",
    "    # Print the extracted lines\n",
    "    quotes = []\n",
    "    pattern2 = r'\"([^\"]+)\"\\s*-\\s*(.+)'\n",
    "\n",
    "    for line in lines_with_stripped_numbers:\n",
    "        match = re.search(pattern2, line)\n",
    "        q = match.group(1)\n",
    "        w = match.group(2)\n",
    "        quotes.append((q, w))\n",
    "    return quotes\n",
    "\n",
    "\n",
    "quotes = get_quotes(response[\"result\"])\n",
    "quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score New Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def score_quotes(quotes=None):\n",
    "    \"\"\"Score a list of quotes that have been generated by an LLM string prompt.\n",
    "\n",
    "    quotes example:\n",
    "    [('Dripping water hollows out stone, not through force but through persistence.',\n",
    "    'Metamorphoses'),\n",
    "\n",
    "    \"\"\"\n",
    "    if quotes is None:\n",
    "        quotes = []\n",
    "\n",
    "    # Define the regex pattern\n",
    "    pattern = r\"(\\d+\\.\\d+)\"\n",
    "\n",
    "    # Get the quote string (not the work)\n",
    "    quotes_text = [q[0] for q in quotes]\n",
    "    quotes_work = [q[1] for q in quotes]\n",
    "\n",
    "    # Extract the scores\n",
    "    scores = []\n",
    "    score_reasons = []\n",
    "    for q in quotes_text:\n",
    "        r = chain.invoke({\"text\": q})\n",
    "        r = \" \".join(r)\n",
    "        score_reasons.append(r)\n",
    "        match = re.search(pattern, r)\n",
    "        score = match[0] if match else -1\n",
    "        scores.append(score)\n",
    "    return list(zip(*(scores, score_reasons, quotes_text, quotes_work)))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "scored_quotes = score_quotes(quotes)\n",
    "scored_quotes_df = pd.DataFrame(\n",
    "    scored_quotes, columns=[\"score\", \"reason\", \"quote\", \"work\"]\n",
    ")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "scored_quotes_df  # [\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-Based Quotation Recommendation\n",
    "\n",
    "Resource:\n",
    "* https://arxiv.org/pdf/2005.08319.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of Retrieval Accuracy\n",
    "\n",
    "The below uses current pipeline for 2 reasons:\n",
    "1) To assess the hulicination affect against current pipeline\n",
    "2) To assess scoring variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "non_ovid_generated_quotes = [\n",
    "    \"One man's meat is another man's poison.\",\n",
    "    \"Fortune favors the bold.\",\n",
    "    \"Wherever there is a human being, there is an opportunity for a kindness.\",\n",
    "    \"Love is a kind of warfare.\",\n",
    "    \"One man's meat is another man's poison.\",\n",
    "    \"To be loved, be lovable.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = r\"(\\d+\\.\\d+)\"\n",
    "\n",
    "\n",
    "scores = []\n",
    "strings = []\n",
    "for q in non_ovid_generated_quotes:\n",
    "    r = chain.invoke({\"text\": q})\n",
    "    r = \" \".join(r)\n",
    "    strings.append(r)\n",
    "    match = re.search(pattern, r)\n",
    "    score = match[0] if match else -1\n",
    "    scores.append(score)\n",
    "    print(r)\n",
    "\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"questionable_quote\": non_ovid_generated_quotes,\n",
    "        \"authorship_match_score\": scores,\n",
    "        \"is_original\": [0, 0, 0, 1, 0, 1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_quotes_df[scored_quotes_df[\"score\"].astype(float) < 0.5][\"quote\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Compare to quotes\n",
    "generated_quotes = scored_quotes_df[scored_quotes_df[\"score\"].astype(float) > 0.5][\n",
    "    \"quote\"\n",
    "].tolist()\n",
    "\n",
    "# Read in existing quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process each quote and calculate similarity scores\n",
    "similarity_data = []\n",
    "\n",
    "for generated_quote, actual_quote in product(generated_quotes, df[\"Quote\"]):\n",
    "    # Process the quotes with spaCy\n",
    "    doc_generated = nlp(generated_quote)\n",
    "    doc_actual = nlp(actual_quote)\n",
    "\n",
    "    # Calculate similarity score\n",
    "    similarity_score = doc_generated.similarity(doc_actual)\n",
    "\n",
    "    # Append data to the list\n",
    "    similarity_data.append(\n",
    "        {\n",
    "            \"generated_quotes\": generated_quote,\n",
    "            \"actual_quotes\": actual_quote,\n",
    "            \"similarity_score\": similarity_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a DataFrame from the similarity data\n",
    "similarity_df = pd.DataFrame(similarity_data).sort_values(\n",
    "    \"similarity_score\", ascending=False\n",
    ")\n",
    "display(similarity_df.head(2))\n",
    "\n",
    "# Seems like there might be a magic number similarity score < 0.65\n",
    "print(\"unique quutes\")\n",
    "\n",
    "similiar_quotes = similarity_df[similarity_df[\"similarity_score\"] > 0.65][\n",
    "    \"generated_quotes\"\n",
    "].unique()\n",
    "\n",
    "# Filter out the similar quotes\n",
    "new_quotes = similarity_df[~similarity_df[\"generated_quotes\"].isin(similiar_quotes)][\n",
    "    \"generated_quotes\"\n",
    "].unique()\n",
    "\n",
    "# Get the works for the new quotes\n",
    "new_quote_works = []\n",
    "for q in new_quotes:\n",
    "    for quote, work in quotes:\n",
    "        if q == quote:\n",
    "            new_quote_works.append(work)\n",
    "df_new_quotes = pd.DataFrame(\n",
    "    list(zip(*(new_quotes, new_quote_works))), columns=[\"Quote\", \"Work\"]\n",
    ")\n",
    "df_new_quotes[\"Quote in Latin\"] = None\n",
    "df_new_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similiar_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"highest score comparison:\")\n",
    "idx = 54\n",
    "print(\"GENERATED:\", similarity_df.iloc[54][\"generated_quotes\"])\n",
    "print(\"ACTUAL:\", similarity_df.iloc[54][\"actual_quotes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage of Additional Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Quote in Latin</th>\n",
       "      <th>Work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love is a thing full of anxious fears.</td>\n",
       "      <td>Res est solliciti plena timoris amor.</td>\n",
       "      <td>Heroides (The Heroines), I, 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now are fields of corn where Troy once stood.</td>\n",
       "      <td>Iam seges est ubi Troia fuit.</td>\n",
       "      <td>Heroides (The Heroines), I, 53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Quote  \\\n",
       "0         Love is a thing full of anxious fears.   \n",
       "1  Now are fields of corn where Troy once stood.   \n",
       "\n",
       "                          Quote in Latin                            Work  \n",
       "0  Res est solliciti plena timoris amor.  Heroides (The Heroines), I, 12  \n",
       "1          Iam seges est ubi Troia fuit.  Heroides (The Heroines), I, 53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe shape: (51, 3)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read in the existing dataframe\n",
    "# df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# # Manually append a new row to the dataframe\n",
    "# new_row = {\n",
    "#     \"Quote\": \"Greet them (others) by their names it costs you nothing.\",\n",
    "#     \"Work\": \"Ars Amatoria\",\n",
    "#     \"Quote in Latin\": \"\",\n",
    "# }\n",
    "# df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# # Print the updated dataframe\n",
    "# display(df.head(2))\n",
    "# df.to_json(\"./../app/ovid_quotes.json\")\n",
    "# print(\"New dataframe shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After quotes works have passed the assessment bars above\n",
    "df = pd.concat([df, df_new_quotes]).reset_index(drop=True)\n",
    "df.to_json(\"./../ovid_quotes.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmoresV2.pdf\n",
      "AmoresV2.txt\n",
      "Amours.txt\n",
      "Fasti.txt\n",
      "FastiV2.pdf\n",
      "FastiV2.txt\n",
      "Heroides.pdf\n",
      "Heroides.txt\n",
      "HeroidesV2.txt\n",
      "LastPoems.txt\n",
      "LostPoemsV2.txt\n",
      "LoversAssistant.txt\n",
      "MetamorphosesI_VII.txt\n",
      "MetamorphosesV2.pdf\n",
      "MetamorphosesV2.txt\n",
      "MetamorphosesVIII_XV.txt\n",
      "MetamorphosesofPublius.txt\n",
      "RemediaAmoris.txt\n",
      "lostpoems.pdf\n",
      "notes.jsonl\n",
      "notes_validation.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  302k  100  302k    0     0   380k      0 --:--:-- --:--:-- --:--:--  381k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ../data\n",
    "curl https://web.seducoahuila.gob.mx/biblioweb/upload/THE%20ART%20OF%20LOVE.pdf > ../data/ArsAmatoria.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Initialize an empty string to store the extracted text\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        # Iterate through pages and extract text\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            extracted_text += page.get_text()\n",
    "\n",
    "        return extracted_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "pdf_file_path = \"/Users/aus10powell/Downloads/TheOdesofHorace_10227561.pdf\"  # Replace with the path to your PDF file\n",
    "extracted_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "\n",
    "def save_text_to_txt(text, pdf_path):\n",
    "    txt_path = pdf_path[:-4] + \".txt\"  # Assuming the PDF file has a \".pdf\" extension\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "        txt_file.write(text)\n",
    "\n",
    "\n",
    "save_text_to_txt(extracted_text, \"../data/TheOdesofHorace_10227561(3).txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eat.',\n",
       " 'As',\n",
       " 'her',\n",
       " 'breath',\n",
       " 'returned,',\n",
       " 'she',\n",
       " 'tore',\n",
       " 'the',\n",
       " 'thin',\n",
       " 'clothing']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(extracted_text.split()))\n",
    "extracted_text.split()[-1000:-990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file created successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/ArsAmatoria.txt\"\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(extracted_text)\n",
    "\n",
    "print(\"Text file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Quote Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# import utils\n",
    "import configparser\n",
    "from pprint import pprint\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "f1 = \"./../data/LostPoemsV2.txt\"\n",
    "f2 = \"./../data/FastiV2.txt\"\n",
    "\n",
    "docs = [f1, f2]\n",
    "documents = SimpleDirectoryReader(input_files=docs).load_data()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=25)\n",
    "texts = text_splitter.create_documents(docs)\n",
    "directory = \"index_store\"\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local(\"index_store\", OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but as an AI language model, I do not have the ability to browse specific files or access specific quotes from works of literature. I recommend reading Ovid's works, such as \"Lost Poems\" and \"Fasti,\" to discover and appreciate the memorable quotes within them.\n"
     ]
    }
   ],
   "source": [
    "qa_interface = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "response = qa_interface(\n",
    "    \"\"\"\n",
    "I am a big fan of ovid. \n",
    "Please recommend memorable quotes to me.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
