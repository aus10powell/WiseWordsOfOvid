{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quote Generation/Retrieval\n",
    "\n",
    "Initial quotes were scraped from one webpage. But that would lead to quite a lot of repitition and kindof a boring bot. So...\n",
    "\n",
    "### 2 Issues with Index retrieved/Generated Quotes:\n",
    "**Goal:** To have ~100 quotes to have tweeted on a rolling basis since this is a quarter of a year and will not likely to be easily repeated.\n",
    "\n",
    "### Probability of Repeating a Quote Exactly 2 Weeks Later\n",
    "\n",
    "\\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) = 1 - \\left( \\frac{N - 1}{N} \\right)^{\\frac{14}{m}}\n",
    "\\end{equation*}\n",
    "\n",
    " Substituting in the values:\n",
    "\n",
    " \\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) = 1 - \\left( \\frac{99}{100} \\right)^{14}\n",
    "\\end{equation*}\n",
    "\n",
    " Calculating this gives:\n",
    "\n",
    " \\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) \\approx 0.135\n",
    "\\end{equation*}\n",
    "\n",
    "Personally, I'd like it to be under 10% for a longer period of time (increases probability)\n",
    "\n",
    "Tweaking the numbers a bit \n",
    "N = 200\n",
    "days = 21\n",
    "\n",
    "\\begin{equation*}\n",
    "P(\\text{repeated in 3 weeks}) \\approx  0.0980\n",
    "\\end{equation*}\n",
    "\n",
    "The following should be conditional 1) That the quote generated has confidence that the quote was written by Ovid then 2) That the quote is not a variation of a quote already in DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# import utils\n",
    "import configparser\n",
    "from pprint import pprint\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()\n",
    "# Access values from the sections\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../app\")\n",
    "import conn_utils\n",
    "\n",
    "OPENAI_API_KEY = conn_utils.get_open_ai_key(\"./../app/config.ini\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "directory = \"index_store\"\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amours.txt                 MetamorphosesVIII_XV.txt\n",
      "Fasti.txt                  MetamorphosesofPublius.txt\n",
      "Heroides.txt               RemediaAmoris.txt\n",
      "LastPoems.txt              notes.jsonl\n",
      "LoversAssistant.txt        notes_validation.jsonl\n",
      "MetamorphosesI_VII.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ./../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get low sentency similarity\n",
    "\n",
    "Instead of using a LLM. You can trust to get a close (but not too close) similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sentences: 3752\n",
      "['\\ufeffThe Project Gutenberg eBook of The Amores; or, Amours\\n'\n",
      " '    \\n'\n",
      " 'This ebook is for the use of anyone anywhere in the United States and\\n'\n",
      " 'most other parts of the world at no cost and with almost no restrictions\\n'\n",
      " 'whatsoever.',\n",
      " 'You may copy it, give it away or re-use it under the terms\\n'\n",
      " 'of the Project Gutenberg License included with this ebook or online\\n'\n",
      " 'at www.gutenberg.org.',\n",
      " 'If you are not located in the United States,\\n'\n",
      " 'you will have to check the laws of the country where you are located\\n'\n",
      " 'before using this eBook.\\n'\n",
      " '\\n',\n",
      " 'Title: The Amores; or, Amours\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Author: Ovid\\n'\n",
      " '\\n'\n",
      " 'Translator: Henry T. Riley\\n'\n",
      " '\\n'\n",
      " 'Release date: December 16, 2014 [eBook #47676]\\n'\n",
      " '\\n'\n",
      " 'Language: English\\n'\n",
      " '\\n'\n",
      " 'Credits: Produced by David Widger from page images generously\\n'\n",
      " '        provided by the Internet Archive\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '*** START OF THE PROJECT GUTENBERG EBOOK THE AMORES; OR, AMOURS ***\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Produced by David Widger from page images generously\\n'\n",
      " 'provided by the Internet Archive\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'THE AMORES;\\n'\n",
      " '\\n'\n",
      " 'or, AMOURS\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'By Ovid\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Literally Translated into English Prose, with Copious Notes, by Henry T. '\n",
      " 'Riley\\n'\n",
      " '\\n'\n",
      " '1885\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'BOOK THE FIRST.\\n'\n",
      " '\\n',\n",
      " 'AN EPIGRAM ON THE AMOURS.\\n\\n',\n",
      " '|We who of late were five books',\n",
      " '[001] of Naso, are now but three: this\\n'\n",
      " 'work our author has preferred to the former one.',\n",
      " 'Though it should [002]\\n'\n",
      " 'now be no pleasure to thee to read us; still, the labour will be less,\\n'\n",
      " 'the two being removed.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n',\n",
      " 'ELEGY I.\\n\\n_',\n",
      " 'He says that he is compelled by Cupid to write of love instead of\\n'\n",
      " 'battles and that the Divinity insists on making each second Hexameter\\n'\n",
      " 'line into a Pentameter._\\n'\n",
      " '\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Read in exisitng quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the file paths\n",
    "files = [\n",
    "    \"RemediaAmoris.txt\",\n",
    "    \"Heroides.txt\",\n",
    "    \"Amours.txt\",\n",
    "    \"Fasti.txt\",\n",
    "    \"MetamorphosesI_VII.txt\",\n",
    "    \"MetamorphosesVIII_XV.txt\",\n",
    "    \"MetamorphosesofPublius.txt\",\n",
    "    \"LoversAssistant.txt\",\n",
    "    \"LastPoems.txt\",\n",
    "]\n",
    "\n",
    "# Read in the text files and split sentences\n",
    "from tqdm import tqdm\n",
    "\n",
    "sentences = []\n",
    "for file in tqdm([\"Amours.txt\"]):\n",
    "    with open(os.path.join(\"./../data\", file), \"r\") as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        sentences.extend([sent.text for sent in doc.sents])\n",
    "\n",
    "# Print the list of sentences\n",
    "print(f\"Num sentences: {len(sentences)}\")\n",
    "pprint(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Project Gutenberg eBook of The Amores or Amours '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\\ufeffThe Project Gutenberg eBook of The Amores; or, Amours\\n\"\n",
    "re.sub(\"[^0-9a-zA-Z]+\", \" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2619\n",
      "['If you are not located in the United States you will have to check the laws '\n",
      " 'of the country where you are located before using this eBook',\n",
      " 'AN EPIGRAM ON THE AMOURS',\n",
      " 'We who of late were five books',\n",
      " '001 of Naso are now but three this work our author has preferred to the '\n",
      " 'former one',\n",
      " 'Though it should 002 now be no pleasure to thee to read us still the labour '\n",
      " 'will be less the two being removed']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def replace_non_alphanumeric(input_string):\n",
    "    return re.sub(\"[^0-9a-zA-Z]+\", \" \", input_string)\n",
    "\n",
    "\n",
    "# Clean sentences\n",
    "sentences = [\n",
    "    replace_non_alphanumeric(input_string=s).strip()\n",
    "    for s in sentences\n",
    "    if len(s.replace(\"\\n\", \"\").strip().split()) > 2\n",
    "]\n",
    "\n",
    "sentences = [s for s in sentences if \"Footnote\" not in s]\n",
    "sentences = [s for s in sentences if \"Project Gutenberg\" not in s]\n",
    "sentences = [s for s in sentences if \"--Ver.\" not in s]\n",
    "sentences = [s for s in sentences if \"The Amores\" not in s]\n",
    "print(len(sentences))\n",
    "pprint(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to temp disk\n",
    "# Define the file path\n",
    "file_path = \"/Users/aus10powell/Downloads/sentences.json\"\n",
    "\n",
    "pd.DataFrame({\"sentences\": sentences}).to_json(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = product(sentences, df[\"Quote\"])\n",
    "t = list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/gdppvj912kv3ds7_xnf0q_fc0000gn/T/ipykernel_36937/2330900647.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_score = doc_generated.similarity(doc_actual)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Let the man who does not wish to be idle fall in love!',\n",
       " 'To love and be loved is to feel the sun from both sides.',\n",
       " \"Love yields to business. If you seek a way out of love, be busy; you'll be safe then.\",\n",
       " 'Happy is the man who has broken the chains which hurt the mind, and has given up worrying once and for all.',\n",
       " 'Nothing is stronger than habit.',\n",
       " 'Dripping water hollows out stone, not through force but through persistence.',\n",
       " 'It is no use to blame the looking glass if your face is awry.',\n",
       " 'Resist beginnings; the remedy comes too late when the disease has gained strength by long delays.',\n",
       " 'The mind, conscious of rectitude, laughed to scorn the falsehood of report.',\n",
       " 'The cause is hidden. The effect is visible to all.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################\n",
    "# POC: To see if generate a response based on a quote\n",
    "# Situation: There is a general tweet\n",
    "# Task: Generate a list of candidate quotes\n",
    "# Action: Create a model that assigns a score to each quote\n",
    "# Result: The top 1 quote is returned\n",
    "##################################################################################################################################################\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Read in exisitng quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "sentences = df[\"Quote\"].tolist()\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "actual_quote = \"People will do anything, no matter how absurd, in order to avoid facing their own souls. One does not become enlightened by imagining figures of light, but by making the darkness conscious.\"\n",
    "doc_actual = nlp(actual_quote)\n",
    "similarity_data = []\n",
    "for s in sentences:\n",
    "    doc_generated = nlp(s)\n",
    "    similarity_score = doc_generated.similarity(doc_actual)\n",
    "    similarity_data.append(\n",
    "        {\n",
    "            \"new_quotes\": s,\n",
    "            \"actual_quotes\": actual_quote,\n",
    "            \"similarity_score\": similarity_score,\n",
    "        }\n",
    "    )\n",
    "similarity_df = pd.DataFrame(similarity_data)\n",
    "similarity_df = similarity_df.sort_values(by=\"similarity_score\", ascending=False).head(10)\n",
    "similarity_df[\"new_quotes\"].to_list()[:10]\n",
    "##################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89046 [00:00<?, ?it/s]/var/folders/qq/gdppvj912kv3ds7_xnf0q_fc0000gn/T/ipykernel_33325/2469827673.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_score = doc_generated.similarity(doc_actual)\n",
      "100%|██████████| 89046/89046 [34:33<00:00, 42.95it/s]    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11299</th>\n",
       "      <td>Let him who wishes not to become slothful fall in love</td>\n",
       "      <td>Let the man who does not wish to be idle fall in love!</td>\n",
       "      <td>0.767422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83568</th>\n",
       "      <td>He alludes to the custom of the nearest relative closing the eyes of the dying person</td>\n",
       "      <td>The mind moves in the direction of our currently dominant thoughts.</td>\n",
       "      <td>0.762584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10536</th>\n",
       "      <td>The one watches at the door of his mistress but the other at that of his general</td>\n",
       "      <td>The mind moves in the direction of our currently dominant thoughts.</td>\n",
       "      <td>0.760010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  new_quotes  \\\n",
       "11299                                 Let him who wishes not to become slothful fall in love   \n",
       "83568  He alludes to the custom of the nearest relative closing the eyes of the dying person   \n",
       "10536       The one watches at the door of his mistress but the other at that of his general   \n",
       "\n",
       "                                                             actual_quotes  \\\n",
       "11299               Let the man who does not wish to be idle fall in love!   \n",
       "83568  The mind moves in the direction of our currently dominant thoughts.   \n",
       "10536  The mind moves in the direction of our currently dominant thoughts.   \n",
       "\n",
       "       similarity_score  \n",
       "11299          0.767422  \n",
       "83568          0.762584  \n",
       "10536          0.760010  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56813, 3)\n",
      "(56016, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47230</th>\n",
       "      <td>645 Bearing these things and others on which I am silent I have oft endured them find another in my stead who could put up with these things</td>\n",
       "      <td>Let him who loves, where love success may find, Spread all his sails before the prosp'rous wind.</td>\n",
       "      <td>0.462355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14586</th>\n",
       "      <td>Why should I be punished in my affections if thy husband does decay through length of years</td>\n",
       "      <td>Love is a thing full of anxious fears.</td>\n",
       "      <td>0.362743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67507</th>\n",
       "      <td>As Assyria adjoined India the word Assyrium is here used by poetical licence as really meaning Indian</td>\n",
       "      <td>The cause is hidden, but the effect is visible to all.</td>\n",
       "      <td>0.260701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40552</th>\n",
       "      <td>Her the impetuous stream beheld from his rapid waves and raised his hoarse mouth from the midst of his fords and thus he said Why in sorrow art thou pacing my banks Ilia the descendant of Laomedon</td>\n",
       "      <td>Fortune and love favor the brave.</td>\n",
       "      <td>0.313440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29470</th>\n",
       "      <td>that I could suddenly be changed into my own present by the arts of her of a or of the Carpathian old man</td>\n",
       "      <td>It is no use to blame the looking glass if your face is awry.</td>\n",
       "      <td>0.369159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>I myself though destined as I am to die a more pleasing death by love should have beheld no days had my mother slain me</td>\n",
       "      <td>And did you, my hands, seize the horns of the mighty bull?</td>\n",
       "      <td>0.297777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>my hair let anger nerve your hands weak though they may be</td>\n",
       "      <td>The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”</td>\n",
       "      <td>0.285236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82868</th>\n",
       "      <td>A certain poetic measure was called by this name but we learn from Athenaeus that it was not always confined to pathetic subjects</td>\n",
       "      <td>Every lover is a soldier.</td>\n",
       "      <td>0.286260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45634</th>\n",
       "      <td>To her said Nemesis What dost thou say</td>\n",
       "      <td>Love yields to business. If you seek a way out of love, be busy; you'll be safe then.</td>\n",
       "      <td>0.211255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66827</th>\n",
       "      <td>Hippolytus was an example of chastity while Priapus was the very ideal of lustfulness</td>\n",
       "      <td>The cause is hidden, but the effect is visible to all.</td>\n",
       "      <td>0.357871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                 new_quotes  \\\n",
       "47230                                                          645 Bearing these things and others on which I am silent I have oft endured them find another in my stead who could put up with these things   \n",
       "14586                                                                                                           Why should I be punished in my affections if thy husband does decay through length of years   \n",
       "67507                                                                                                 As Assyria adjoined India the word Assyrium is here used by poetical licence as really meaning Indian   \n",
       "40552  Her the impetuous stream beheld from his rapid waves and raised his hoarse mouth from the midst of his fords and thus he said Why in sorrow art thou pacing my banks Ilia the descendant of Laomedon   \n",
       "29470                                                                                             that I could suddenly be changed into my own present by the arts of her of a or of the Carpathian old man   \n",
       "28830                                                                               I myself though destined as I am to die a more pleasing death by love should have beheld no days had my mother slain me   \n",
       "7789                                                                                                                                             my hair let anger nerve your hands weak though they may be   \n",
       "82868                                                                     A certain poetic measure was called by this name but we learn from Athenaeus that it was not always confined to pathetic subjects   \n",
       "45634                                                                                                                                                                To her said Nemesis What dost thou say   \n",
       "66827                                                                                                                 Hippolytus was an example of chastity while Priapus was the very ideal of lustfulness   \n",
       "\n",
       "                                                                                                                                                                    actual_quotes  \\\n",
       "47230                                                                            Let him who loves, where love success may find, Spread all his sails before the prosp'rous wind.   \n",
       "14586                                                                                                                                      Love is a thing full of anxious fears.   \n",
       "67507                                                                                                                      The cause is hidden, but the effect is visible to all.   \n",
       "40552                                                                                                                                           Fortune and love favor the brave.   \n",
       "29470                                                                                                               It is no use to blame the looking glass if your face is awry.   \n",
       "28830                                                                                                                  And did you, my hands, seize the horns of the mighty bull?   \n",
       "7789   The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”   \n",
       "82868                                                                                                                                                   Every lover is a soldier.   \n",
       "45634                                                                                       Love yields to business. If you seek a way out of love, be busy; you'll be safe then.   \n",
       "66827                                                                                                                      The cause is hidden, but the effect is visible to all.   \n",
       "\n",
       "       similarity_score  \n",
       "47230          0.462355  \n",
       "14586          0.362743  \n",
       "67507          0.260701  \n",
       "40552          0.313440  \n",
       "29470          0.369159  \n",
       "28830          0.297777  \n",
       "7789           0.285236  \n",
       "82868          0.286260  \n",
       "45634          0.211255  \n",
       "66827          0.357871  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_data = []\n",
    "\n",
    "for generated_quote, actual_quote in tqdm(t):\n",
    "    # Process the quotes with spaCy\n",
    "    doc_generated = nlp(generated_quote)\n",
    "    doc_actual = nlp(actual_quote)\n",
    "\n",
    "    # Calculate similarity score\n",
    "    similarity_score = doc_generated.similarity(doc_actual)\n",
    "\n",
    "    # Append data to the list\n",
    "    similarity_data.append(\n",
    "        {\n",
    "            \"new_quotes\": generated_quote,\n",
    "            \"actual_quotes\": actual_quote,\n",
    "            \"similarity_score\": similarity_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a DataFrame from the similarity data\n",
    "similarity_df = pd.DataFrame(similarity_data).sort_values(\n",
    "    \"similarity_score\", ascending=False\n",
    ")\n",
    "display(similarity_df.head(3))\n",
    "\n",
    "# Sort and clean\n",
    "upper_similarity = 0.8\n",
    "lower_similarity = 0.2\n",
    "\n",
    "suitable_df = similarity_df[\n",
    "    (similarity_df[\"similarity_score\"] > lower_similarity)\n",
    "    & (similarity_df[\"similarity_score\"] < upper_similarity)\n",
    "].sort_values(\n",
    "    \"similarity_score\", ascending=True\n",
    ")  # .sample(10)\n",
    "print(suitable_df.shape)\n",
    "# Clean out very short quotes\n",
    "suitable_df = suitable_df[suitable_df[\"new_quotes\"].str.len() > 20]\n",
    "# suitable_df = suitable_df[~suitable_df[\"new_quotes\"].str.contains(\"Footnote\")]\n",
    "# suitable_df = suitable_df[~suitable_df[\"new_quotes\"].str.contains(\"--Ver.\")]\n",
    "print(suitable_df.shape)\n",
    "suitable_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19431</th>\n",
       "      <td>the young\\nLady began to change her Note, and to hope he would not forsake her\\nso.\\n\\n</td>\n",
       "      <td>The cause is hidden, but the effect is visible to all.</td>\n",
       "      <td>0.222706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8661</th>\n",
       "      <td>Believe every Woman is to be\\ncome at.</td>\n",
       "      <td>To love and be loved is to feel the sun from both sides.</td>\n",
       "      <td>0.587393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10582</th>\n",
       "      <td>Agamemnon_, after returning safe from so many bloody Campaigns, and\\nfrom the dangerous Seas which he crossed, fell at last a dreadful\\nVictim to the Whore his Wife[37].\\n\\n</td>\n",
       "      <td>There is a god within us.</td>\n",
       "      <td>0.333108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11316</th>\n",
       "      <td>When your Mistress is in this Humour, let _Abigail_</td>\n",
       "      <td>Happy is the man who has broken the chains which hurt the mind, and has given up worrying once and for all.</td>\n",
       "      <td>0.266805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>Evie Evoe_, two very mysterious Words, and\\nfull of Masonry, the God and his new-ravished Bride go together,\\nbetween a Pair of sacred Sheets.\\n\\n</td>\n",
       "      <td>The mind can make a heaven of hell, a hell of heaven.</td>\n",
       "      <td>0.484700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>It is moreover my Advice to you, to be liberal of your Promises; for\\nwhat Injury can you receive by Promising?</td>\n",
       "      <td>Love is a kind of warfare.</td>\n",
       "      <td>0.338792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12419</th>\n",
       "      <td>\"I promise you, my Dear,\" says she, \"if you will but buy me this\\nsingle Jewel, I will not ask another of you the Lord knows how long;\\nbut I have really a present Occasion for this, and besides it is the\\ncheapest Thing I ever saw.</td>\n",
       "      <td>The mind, conscious of rectitude, laughed to scorn the falsehood of report.</td>\n",
       "      <td>0.230278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>It\\nis well known that the [1]Rules of Art are necessary to the Conduct of\\na Ship; for which reason, none but able and experienced Seamen are\\npreferred to the Command of one.</td>\n",
       "      <td>To love and be loved is to feel the sun from both sides.</td>\n",
       "      <td>0.337503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25593</th>\n",
       "      <td>Caunus_; and\\nupon his rejecting her Addresses, hanged herself.</td>\n",
       "      <td>To love and be loved is to feel the sun from both sides.</td>\n",
       "      <td>0.283958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>Fie upon it, General, I am ashamed to see you sit quilting among the\\nGirls; a Sword becomes your Hands much better than a Needle._\\n\\n_</td>\n",
       "      <td>Far away be that fate!</td>\n",
       "      <td>0.286274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                     new_quotes  \\\n",
       "19431                                                                                                                                                   the young\\nLady began to change her Note, and to hope he would not forsake her\\nso.\\n\\n   \n",
       "8661                                                                                                                                                                                                     Believe every Woman is to be\\ncome at.   \n",
       "10582                                                             Agamemnon_, after returning safe from so many bloody Campaigns, and\\nfrom the dangerous Seas which he crossed, fell at last a dreadful\\nVictim to the Whore his Wife[37].\\n\\n   \n",
       "11316                                                                                                                                                                                       When your Mistress is in this Humour, let _Abigail_   \n",
       "15899                                                                                        Evie Evoe_, two very mysterious Words, and\\nfull of Masonry, the God and his new-ravished Bride go together,\\nbetween a Pair of sacred Sheets.\\n\\n   \n",
       "12837                                                                                                                           It is moreover my Advice to you, to be liberal of your Promises; for\\nwhat Injury can you receive by Promising?   \n",
       "12419  \"I promise you, my Dear,\" says she, \"if you will but buy me this\\nsingle Jewel, I will not ask another of you the Lord knows how long;\\nbut I have really a present Occasion for this, and besides it is the\\ncheapest Thing I ever saw.   \n",
       "3017                                                           It\\nis well known that the [1]Rules of Art are necessary to the Conduct of\\na Ship; for which reason, none but able and experienced Seamen are\\npreferred to the Command of one.   \n",
       "25593                                                                                                                                                                           Caunus_; and\\nupon his rejecting her Addresses, hanged herself.   \n",
       "19018                                                                                                  Fie upon it, General, I am ashamed to see you sit quilting among the\\nGirls; a Sword becomes your Hands much better than a Needle._\\n\\n_   \n",
       "\n",
       "                                                                                                     actual_quotes  \\\n",
       "19431                                                       The cause is hidden, but the effect is visible to all.   \n",
       "8661                                                      To love and be loved is to feel the sun from both sides.   \n",
       "10582                                                                                    There is a god within us.   \n",
       "11316  Happy is the man who has broken the chains which hurt the mind, and has given up worrying once and for all.   \n",
       "15899                                                        The mind can make a heaven of hell, a hell of heaven.   \n",
       "12837                                                                                   Love is a kind of warfare.   \n",
       "12419                                  The mind, conscious of rectitude, laughed to scorn the falsehood of report.   \n",
       "3017                                                      To love and be loved is to feel the sun from both sides.   \n",
       "25593                                                     To love and be loved is to feel the sun from both sides.   \n",
       "19018                                                                                       Far away be that fate!   \n",
       "\n",
       "       similarity_score  \n",
       "19431          0.222706  \n",
       "8661           0.587393  \n",
       "10582          0.333108  \n",
       "11316          0.266805  \n",
       "15899          0.484700  \n",
       "12837          0.338792  \n",
       "12419          0.230278  \n",
       "3017           0.337503  \n",
       "25593          0.283958  \n",
       "19018          0.286274  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suitable_df = suitable_df[suitable_df[\"new_quotes\"].str.len() > 20]\n",
    "suitable_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "# ## Update add new quotes to the dataframe\n",
    "# new_row = {\n",
    "#     \"Quote\": \"Let anger nerve your hands weak though they may be.\",\n",
    "#     \"Work\": \"Amores\",\n",
    "#     \"Quote in Latin\": \"Ira vires anima manus, quamvis infirmae sint.\",\n",
    "# }\n",
    "# df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "# df.to_json(\"./../app/ovid_quotes.json\")\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "DATA_DIR = \"./../data\"\n",
    "files = [\n",
    "    \"RemediaAmoris.txt\",\n",
    "    \"Heroides.txt\",\n",
    "    \"Amours.txt\",\n",
    "    \"Fasti.txt\",\n",
    "    \"MetamorphosesI_VII.txt\",\n",
    "    \"MetamorphosesVIII_XV.txt\",\n",
    "    \"MetamorphosesofPublius.txt\",\n",
    "    \"LoversAssistant.txt\",\n",
    "    \"LastPoems.txt\",\n",
    "]\n",
    "docs = [f\"{DATA_DIR}/{file}\" for file in files]\n",
    "documents = SimpleDirectoryReader(input_files=docs).load_data()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=25)\n",
    "texts = text_splitter.create_documents(docs)\n",
    "directory = \"index_store\"\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local(\"index_store\", OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_interface = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "response = qa_interface(\n",
    "    f\"\"\"\n",
    "I am a big fan of ovid. \n",
    "Please recommend 10 memorable quotes to me along with the source document they were taken from.\n",
    "\n",
    "Do NOT include quotes I already have:\n",
    "{df[\"Quote\"].tolist()}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authorship authentication\n",
    "\n",
    "**[Who Wrote it and Why?\n",
    "Prompting Large-Language Models for Authorship Verification](https://arxiv.org/pdf/2310.08123.pdf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Authorship Attribution\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "\n",
    "template = f\"\"\"Task: On a scale of 0 to 1, with 0 indicating low confidence\n",
    "and 1 indicating high confidence, please provide a general\n",
    "assessment of the likelihood that given text \n",
    "written by the same author as the provided reference. Your answer should reflect a\n",
    "moderate level of strictness in scoring. Here are some\n",
    "relevant variables to this problem.\n",
    "1. punctuation style(e.g. hyphen, brackets, colon, comma,\n",
    "parenthesis, quotation mark)\n",
    "2. special characters style, capitalization style(e.g.\n",
    "Continuous capitalization, capitalizing certain words)\n",
    "3. acronyms and abbreviations(e.g. Usage of acronyms\n",
    "such as OMG, Abbreviations without punctuation marks\n",
    "such as Mr Rochester vs. Mr. Rochester,Unusual\n",
    "abbreviations such as def vs. definitely)\n",
    "4. writing style\n",
    "5. expressions and Idioms\n",
    "6. tone and mood\n",
    "7. sentence structure\n",
    "8. any other relevant aspect\n",
    "First step: Understand the problem, extracting relevant\n",
    "variables and devise a plan to solve the problem. Then,\n",
    "carry out the plan and solve the problem step by step.\n",
    "9. One (or both) of the texts is written by the famous Latin author \"Ovid\"\n",
    "Finally, show the confidence score.\n",
    "\n",
    "The following are all quotes by Ovid for reference:\n",
    "'Love is a thing full of anxious fears.',\n",
    " 'Now are fields of corn where Troy once stood.',\n",
    " \"We're slow to believe what wounds us.\",\n",
    " \"The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”\",\n",
    " \"Let him who loves, where love success may find, Spread all his sails before the prosp'rous wind.\",\n",
    " 'Resist beginnings; the remedy comes too late when the disease has gained strength by long delays.',\n",
    " \"Love yields to business. If you seek a way out of love, be busy; you'll be safe then.\",\n",
    " 'The gods behold all righteous actions.',\n",
    " 'There is a god within us.',\n",
    " 'The mind, conscious of rectitude, laughed to scorn the falsehood of report.',\n",
    " 'Every lover is a soldier.',\n",
    " 'Let the man who does not wish to be idle fall in love!',\n",
    " 'Far away be that fate!',\n",
    " 'They bear punishment with equanimity who have earned it.',\n",
    " \"We take no pleasure in permitted joys. But what's forbidden is more keenly sought.\",\n",
    " 'Who is allowed to sin, sins less.' \n",
    " \n",
    " \"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ]\n",
    ")\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Quotes from LLM Authorshipp Attribution\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "input_string = response[\"result\"]\n",
    "\n",
    "\n",
    "def get_quotes(input_string):\n",
    "    \"\"\"Extract quotes from a string that has been created by an LLM string prompt.\"\"\"\n",
    "    # Extract the lines that start with a number\n",
    "    lines_with_stripped_numbers = [\n",
    "        re.sub(r\"^\\d+\\.\\s*\", \"\", line.strip())\n",
    "        for line in input_string.splitlines()\n",
    "        if re.match(r\"^\\d+\\.\", line)\n",
    "    ]\n",
    "\n",
    "    # Print the extracted lines\n",
    "    quotes = []\n",
    "    pattern2 = r'\"([^\"]+)\"\\s*-\\s*(.+)'\n",
    "\n",
    "    for line in lines_with_stripped_numbers:\n",
    "        match = re.search(pattern2, line)\n",
    "        q = match.group(1)\n",
    "        w = match.group(2)\n",
    "        quotes.append((q, w))\n",
    "    return quotes\n",
    "\n",
    "\n",
    "quotes = get_quotes(response[\"result\"])\n",
    "quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score New Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def score_quotes(quotes=None):\n",
    "    \"\"\"Score a list of quotes that have been generated by an LLM string prompt.\n",
    "\n",
    "    quotes example:\n",
    "    [('Dripping water hollows out stone, not through force but through persistence.',\n",
    "    'Metamorphoses'),\n",
    "\n",
    "    \"\"\"\n",
    "    if quotes is None:\n",
    "        quotes = []\n",
    "\n",
    "    # Define the regex pattern\n",
    "    pattern = r\"(\\d+\\.\\d+)\"\n",
    "\n",
    "    # Get the quote string (not the work)\n",
    "    quotes_text = [q[0] for q in quotes]\n",
    "    quotes_work = [q[1] for q in quotes]\n",
    "\n",
    "    # Extract the scores\n",
    "    scores = []\n",
    "    score_reasons = []\n",
    "    for q in quotes_text:\n",
    "        r = chain.invoke({\"text\": q})\n",
    "        r = \" \".join(r)\n",
    "        score_reasons.append(r)\n",
    "        match = re.search(pattern, r)\n",
    "        score = match[0] if match else -1\n",
    "        scores.append(score)\n",
    "    return list(zip(*(scores, score_reasons, quotes_text, quotes_work)))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "scored_quotes = score_quotes(quotes)\n",
    "scored_quotes_df = pd.DataFrame(\n",
    "    scored_quotes, columns=[\"score\", \"reason\", \"quote\", \"work\"]\n",
    ")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "scored_quotes_df  # [\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_quotes_df[\"quote\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-Based Quotation Recommendation\n",
    "\n",
    "Resource:\n",
    "* https://arxiv.org/pdf/2005.08319.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of Retrieval Accuracy\n",
    "\n",
    "The below uses current pipeline for 2 reasons:\n",
    "1) To assess the hulicination affect against current pipeline\n",
    "2) To assess scoring variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "non_ovid_generated_quotes = [\n",
    "    \"One man's meat is another man's poison.\",\n",
    "    \"Fortune favors the bold.\",\n",
    "    \"Wherever there is a human being, there is an opportunity for a kindness.\",\n",
    "    \"Love is a kind of warfare.\",\n",
    "    \"One man's meat is another man's poison.\",\n",
    "    \"To be loved, be lovable.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = r\"(\\d+\\.\\d+)\"\n",
    "\n",
    "\n",
    "scores = []\n",
    "strings = []\n",
    "for q in non_ovid_generated_quotes:\n",
    "    r = chain.invoke({\"text\": q})\n",
    "    r = \" \".join(r)\n",
    "    strings.append(r)\n",
    "    match = re.search(pattern, r)\n",
    "    score = match[0] if match else -1\n",
    "    scores.append(score)\n",
    "    print(r)\n",
    "\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"questionable_quote\": non_ovid_generated_quotes,\n",
    "        \"authorship_match_score\": scores,\n",
    "        \"is_original\": [0, 0, 0, 1, 0, 1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_quotes_df[scored_quotes_df[\"score\"].astype(float) < 0.5][\"quote\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Compare to quotes\n",
    "generated_quotes = scored_quotes_df[scored_quotes_df[\"score\"].astype(float) > 0.5][\n",
    "    \"quote\"\n",
    "].tolist()\n",
    "\n",
    "# Read in existing quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process each quote and calculate similarity scores\n",
    "similarity_data = []\n",
    "\n",
    "for generated_quote, actual_quote in product(generated_quotes, df[\"Quote\"]):\n",
    "    # Process the quotes with spaCy\n",
    "    doc_generated = nlp(generated_quote)\n",
    "    doc_actual = nlp(actual_quote)\n",
    "\n",
    "    # Calculate similarity score\n",
    "    similarity_score = doc_generated.similarity(doc_actual)\n",
    "\n",
    "    # Append data to the list\n",
    "    similarity_data.append(\n",
    "        {\n",
    "            \"generated_quotes\": generated_quote,\n",
    "            \"actual_quotes\": actual_quote,\n",
    "            \"similarity_score\": similarity_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a DataFrame from the similarity data\n",
    "similarity_df = pd.DataFrame(similarity_data).sort_values(\n",
    "    \"similarity_score\", ascending=False\n",
    ")\n",
    "display(similarity_df.head(2))\n",
    "\n",
    "# Seems like there might be a magic number similarity score < 0.65\n",
    "print(\"unique quutes\")\n",
    "\n",
    "similiar_quotes = similarity_df[similarity_df[\"similarity_score\"] > 0.65][\n",
    "    \"generated_quotes\"\n",
    "].unique()\n",
    "\n",
    "# Filter out the similar quotes\n",
    "new_quotes = similarity_df[~similarity_df[\"generated_quotes\"].isin(similiar_quotes)][\n",
    "    \"generated_quotes\"\n",
    "].unique()\n",
    "\n",
    "# Get the works for the new quotes\n",
    "new_quote_works = []\n",
    "for q in new_quotes:\n",
    "    for quote, work in quotes:\n",
    "        if q == quote:\n",
    "            new_quote_works.append(work)\n",
    "df_new_quotes = pd.DataFrame(\n",
    "    list(zip(*(new_quotes, new_quote_works))), columns=[\"Quote\", \"Work\"]\n",
    ")\n",
    "df_new_quotes[\"Quote in Latin\"] = None\n",
    "df_new_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similiar_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"highest score comparison:\")\n",
    "idx = 54\n",
    "print(\"GENERATED:\", similarity_df.iloc[54][\"generated_quotes\"])\n",
    "print(\"ACTUAL:\", similarity_df.iloc[54][\"actual_quotes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage of Additional Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://colab.research.google.com/drive/1Vu8PjdzdnQAebQKFxDMc5cDdLFyF64mJ#scrollTo=20zGRG3Jlrmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After quotes works have passed the assessment bars above\n",
    "df = pd.concat([df, df_new_quotes]).reset_index(drop=True)\n",
    "df.to_json(\"./../ovid_quotes.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "**Format:** Example data from OpenAI for .jsonl\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, \n",
    "            {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \n",
    "            \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import nltk\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "similarity_df[\"actual_quotes\"] = similarity_df[\"actual_quotes\"].apply(preprocess_text)\n",
    "similarity_df[\"new_quotes\"] = similarity_df[\"new_quotes\"].apply(preprocess_text)\n",
    "\n",
    "# Define vocabulary size and embedding dimension\n",
    "max_features = 10000\n",
    "embedding_dim = 128\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Create embedding layers\n",
    "embedding_layer = Embedding(\n",
    "    max_features, embedding_dim, input_length=max_sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 100, 128)             1280000   ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   49408     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 64)                   49408     ['embedding[1][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    129       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1378945 (5.26 MB)\n",
      "Trainable params: 1378945 (5.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define and build the model\n",
    "def build_model():\n",
    "    quote_input = Input(shape=(max_sequence_length,))\n",
    "    new_quote_input = Input(shape=(max_sequence_length,))\n",
    "\n",
    "    embedded_quote = embedding_layer(quote_input)\n",
    "    embedded_new_quote = embedding_layer(new_quote_input)\n",
    "\n",
    "    encoded_quote = LSTM(units=64)(embedded_quote)\n",
    "    encoded_new_quote = LSTM(units=64)(embedded_new_quote)\n",
    "\n",
    "    merged = Concatenate()([encoded_quote, encoded_new_quote])\n",
    "    output = Dense(1, activation=\"softmax\")(merged)\n",
    "\n",
    "    model = Model(inputs=[quote_input, new_quote_input], outputs=output)\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
