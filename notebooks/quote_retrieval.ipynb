{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quote Generation/Retrieval\n",
    "\n",
    "Initial quotes were scraped from one webpage. But that would lead to quite a lot of repitition and kindof a boring bot. So...\n",
    "\n",
    "### 2 Issues with Index retrieved/Generated Quotes:\n",
    "**Goal:** To have ~100 quotes to have tweeted on a rolling basis since this is a quarter of a year and will not likely to be easily repeated.\n",
    "\n",
    "### Probability of Repeating a Quote Exactly 2 Weeks Later\n",
    "\n",
    "\\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) = 1 - \\left( \\frac{N - 1}{N} \\right)^{\\frac{14}{m}}\n",
    "\\end{equation*}\n",
    "\n",
    " Substituting in the values:\n",
    "\n",
    " \\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) = 1 - \\left( \\frac{99}{100} \\right)^{14}\n",
    "\\end{equation*}\n",
    "\n",
    " Calculating this gives:\n",
    "\n",
    " \\begin{equation*}\n",
    "P(\\text{repeated in 2 weeks}) \\approx 0.135\n",
    "\\end{equation*}\n",
    "\n",
    "Personally, I'd like it to be under 10% for a longer period of time (increases probability)\n",
    "\n",
    "Tweaking the numbers a bit \n",
    "N = 200\n",
    "days = 21\n",
    "\n",
    "\\begin{equation*}\n",
    "P(\\text{repeated in 3 weeks}) \\approx  0.0980\n",
    "\\end{equation*}\n",
    "\n",
    "The following should be conditional 1) That the quote generated has confidence that the quote was written by Ovid then 2) That the quote is not a variation of a quote already in DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# import utils\n",
    "import configparser\n",
    "from pprint import pprint\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()\n",
    "# Access values from the sections\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../app\")\n",
    "import conn_utils\n",
    "\n",
    "OPENAI_API_KEY = conn_utils.get_open_ai_key(\"./../app/config.ini\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "directory = \"index_store\"\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmoresV2.txt\n",
      "ArsAmatoria.txt\n",
      "FastiV2.txt\n",
      "HeroidesV2.txt\n",
      "LostPoemsV2.txt\n",
      "LoversAssistant.txt\n",
      "Maze.Runner.The.Death.Cure.2018.1080p.BluRay.x265 [TD].torrent\n",
      "MetamorphosesV2.txt\n",
      "RemediaAmorisV2.txt\n",
      "notes.jsonl\n",
      "notes_validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get low sentency similarity\n",
    "\n",
    "Instead of using a LLM. You can trust to get a close (but not too close) similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sentences: 4988\n",
      "['\\n'\n",
      " 'Translator’s Note: \\n'\n",
      " 'Ovid’s numerous references throughout the Fasti to the \\n'\n",
      " 'rising and setting of stars and constellations, further \\n'\n",
      " 'detailed in the relevant index entries, have been checked \\n'\n",
      " 'using a computer-based astronomical program (Redshift \\n'\n",
      " '4) set to Rome in 8AD.',\n",
      " 'The Kalends, Nones, Ides, and \\n'\n",
      " 'major Festivals of each month are identified in the \\n'\n",
      " 'headings against the relevant days.\\n',\n",
      " '9\\n'\n",
      " 'Book I\\n'\n",
      " 'Book I:Introduction\\n'\n",
      " 'I’ll speak of divisions of time throughout the Roman year,\\n'\n",
      " 'Their origins, and the stars that set beneath the earth and \\n'\n",
      " 'rise.\\n'\n",
      " 'Germanicus Caesar, accept this work, with a calm face,\\n'\n",
      " 'And direct the voyage of my uncertain vessel:\\n'\n",
      " 'Not scorning this slight honour, but like a god, \\n'\n",
      " 'Receiving with favour the homage I pay you.\\n',\n",
      " 'Here you’ll revisit the sacred rites in the ancient texts,\\n'\n",
      " 'And review by what events each day is marked.\\n',\n",
      " 'And here you’ll find the festivals of your House,\\n'\n",
      " 'And see your father’s and your grandfather’s name:\\n'\n",
      " 'The prizes they won, that illustrate the calendar,\\n'\n",
      " 'That you and your brother Drusus will also win.\\n']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Read in exisitng quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Define the file paths\n",
    "f1 = \"./../data/FastiV2.txt\"\n",
    "f2 = \"./../data/MetamorphosesV2.txt\"\n",
    "f3 = \"./../data/AmoresV2.txt\"\n",
    "f4 = \"./../data/LostPoemsV2.txt\"\n",
    "f5 = \"./../data/HeroidesV2.txt\"\n",
    "f6 = \"./../data/ArsAmatoria.txt\"\n",
    "f7 = \"./../data/RemediaAmorisV2.txt\"\n",
    "f8 = \"./../data/LoversAssistant.txt\"\n",
    "\n",
    "# Read in the text files and split sentences\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Override the max length of the text\n",
    "nlp.max_length = 1500000  # or any value that accommodates your text length\n",
    "\n",
    "with open(os.path.join(\"./../data\", \"FastiV2.txt\"), \"r\") as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "sentences = [sent.text for sent in doc.sents]\n",
    "# Print the list of sentences\n",
    "print(f\"Num sentences: {len(sentences)}\")\n",
    "pprint(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "# ## Update add new quotes to the dataframe\n",
    "# new_row = {\n",
    "#     \"Quote\": \"\"\"And yet hard Rocks are hollowed by soft Water.\"\"\",\n",
    "#     \"Work\": \"Fasti\",\n",
    "#     \"Quote in Latin\": \"\",\n",
    "# }\n",
    "# df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "# df.to_json(\"./../app/ovid_quotes.json\")\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n",
      "445\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_sentences(sentences, filter_tokens):\n",
    "    def replace_non_alphanumeric(input_string):\n",
    "        processed_text = re.sub(r\"\\n\", \" \", input_string)\n",
    "        processed_text = re.sub(r\"[^a-zA-Z0-9\\s.,?!'\\-]\", \" \", processed_text)\n",
    "        return processed_text\n",
    "\n",
    "    def contains_filter_tokens(input_string):\n",
    "        return any(token in input_string for token in filter_tokens)\n",
    "\n",
    "    cleaned_sentences = [s.replace(\"\\n\", \". \").replace(\"_\", \" \") for s in sentences]\n",
    "    cleaned_sentences = [replace_non_alphanumeric(s) for s in sentences]\n",
    "    cleaned_sentences = [s for s in cleaned_sentences if len(s.split()) > 4]\n",
    "    cleaned_sentences = [s for s in cleaned_sentences if not contains_filter_tokens(s)]\n",
    "\n",
    "    return cleaned_sentences\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(len(sentences))\n",
    "filter_tokens = [\n",
    "    \"Project Gutenberg\",\n",
    "    \"Footnote\",\n",
    "    \"--Ver.\",\n",
    "    \"The Amores\",\n",
    "    \"United States\",\n",
    "    \"copyright\",\n",
    "    \"Copyright\",\n",
    "    \"gutenberg\",\n",
    "    \"Gutenberg\",\n",
    "]\n",
    "cleaned = clean_sentences(sentences, filter_tokens)\n",
    "print(len(cleaned))\n",
    "\n",
    "# Uncomment to use the clean sentences\n",
    "sentences = clean_sentences(sentences, filter_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6   And as for Miss  Clio \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sampled_cell = random.choice(cleaned)\n",
    "print(sampled_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Before:\n",
      "['It is moreover my Advice to you, to be liberal of your Promises; for\\nwhat Injury can you receive by Promising?', 'This']\n",
      "\n",
      "Sentences After:\n",
      "['which\\nany Man may be rich.\\n\\n', 'Nor can your Mistress complain that she is absolutely cheated, if you\\ncan bring her to believe your Promises.']\n"
     ]
    }
   ],
   "source": [
    "corpus_text = text\n",
    "# The string you want to find\n",
    "target_string = \"is a Treasure in\"\n",
    "\n",
    "# Find the index of the target string\n",
    "start_index = corpus_text.find(target_string)\n",
    "\n",
    "# Ensure the target string is found in the corpus\n",
    "if start_index != -1:\n",
    "    # Extract the text before and after the target string\n",
    "    text_before = corpus_text[:start_index].strip()\n",
    "    text_after = corpus_text[start_index + len(target_string) :].strip()\n",
    "\n",
    "    # Tokenize the sentences using spaCy\n",
    "    doc_before = nlp(text_before)\n",
    "    doc_after = nlp(text_after)\n",
    "\n",
    "    # Get the sentences\n",
    "    sentences_before = [sent.text for sent in doc_before.sents][-2:]\n",
    "    sentences_after = [sent.text for sent in doc_after.sents][:2]\n",
    "\n",
    "    # Print or use the extracted sentences\n",
    "    print(\"Sentences Before:\")\n",
    "    print(sentences_before)\n",
    "\n",
    "    print(\"\\nSentences After:\")\n",
    "    print(sentences_after)\n",
    "else:\n",
    "    print(\"Target string not found in the corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [00:03<00:00, 112.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Note C  An eminent Joyner in  London .    I promise you, my Dear,  says she,  if you will but buy me this single Jewel, I will not ask another of you the Lord knows how long  but I have really a present Occasion for this, and besides it is the cheapest Thing I ever saw.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.874072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                          new_quotes  \\\n",
       "225   Note C  An eminent Joyner in  London .    I promise you, my Dear,  says she,  if you will but buy me this single Jewel, I will not ask another of you the Lord knows how long  but I have really a present Occasion for this, and besides it is the cheapest Thing I ever saw.   \n",
       "\n",
       "                                            actual_quotes  similarity_score  \n",
       "225  My hopes are not always realized, but I always hope.          0.874072  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity_data = []\n",
    "\n",
    "# Sample similarity quotes\n",
    "# But I won t refute a thing  I favour your praise too  For, heart, why reject the voice that is desired? Don t be angry if my belief in you comes only with great  difficulty  trust in important things usually builds slowly.\n",
    "\n",
    "\n",
    "quotes = [\"\"\"My hopes are not always realized, but I always hope.\"\"\"]\n",
    "for actual_quote in quotes:\n",
    "    doc_actual = nlp(actual_quote)\n",
    "\n",
    "    for sent in tqdm(sentences):\n",
    "        doc_generated = nlp(sent)\n",
    "        # Calculate similarity score\n",
    "        similarity_score = doc_generated.similarity(doc_actual)\n",
    "\n",
    "        # Append data to the list\n",
    "        similarity_data.append(\n",
    "            {\n",
    "                \"new_quotes\": doc_generated.text,\n",
    "                \"actual_quotes\": actual_quote,\n",
    "                \"similarity_score\": similarity_score,\n",
    "            }\n",
    "        )\n",
    "# Create a DataFrame from the similarity data\n",
    "similarity_df = pd.DataFrame(similarity_data).sort_values(\n",
    "    \"similarity_score\", ascending=False\n",
    ")\n",
    "display(similarity_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_quotes</th>\n",
       "      <th>actual_quotes</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Hither, from every Corner of the Town, repair the loveliest Nymphs.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.418546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>And yet hard Rocks are hollowed by soft Water.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.600984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>The Story of  Byblis  30  is too well known to be related, who being in love with her Brother, punished her Crime with her own Hands, and hanged herself in her Garters.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.615831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Do this, however, in so gentle a Manner, that you may not hurt her tender Lips  nor let her complain of being scrubbed with your Beard.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.808868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>One thing however I must admonish you,  if my Art deserves any Credit, and my Words are to be regarded as any thing better than Wind</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.872575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Indeed by Candle-light, and in a Side-Box, almost every one is a Beauty  Jewels, Clothes, and Women, are all best discerned by the Light of the Sun.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.423778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>You know the Story of  Cydippe  45 , who was outwitted by a Letter inclosed in an Apple  by which Means she was made to speak Words she never intended.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.515506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Lieutenant-General  Achilles , who was to command a large Body of Grenadiers, which the  Greeks  call  Myrmidons , did not behave handsomely on that Occasion, though he got off afterwards at a Court-Martial by pleading, that his Mother  who had a great deal in her own Power  had insisted on his acting the Part he did  for, I am ashamed to say, he dressed himself in Women's Clothes, and hid himself at the House of one  Lycomedes , a Man of good Fortune in those parts.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.612865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Note D  This is the most exceptionable Passage in the whole Work.</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.374975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Is this the Ravisher you are afraid of?</td>\n",
       "      <td>My hopes are not always realized, but I always hope.</td>\n",
       "      <td>0.640300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    new_quotes  \\\n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                         Hither, from every Corner of the Town, repair the loveliest Nymphs.   \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                           And yet hard Rocks are hollowed by soft Water.     \n",
       "140                                                                                                                                                                                                                                                                                                                 The Story of  Byblis  30  is too well known to be related, who being in love with her Brother, punished her Crime with her own Hands, and hanged herself in her Garters.     \n",
       "381                                                                                                                                                                                                                                                                                                                                                  Do this, however, in so gentle a Manner, that you may not hurt her tender Lips  nor let her complain of being scrubbed with your Beard.     \n",
       "207                                                                                                                                                                                                                                                                                                                                                     One thing however I must admonish you,  if my Art deserves any Credit, and my Words are to be regarded as any thing better than Wind     \n",
       "123                                                                                                                                                                                                                                                                                                                                     Indeed by Candle-light, and in a Side-Box, almost every one is a Beauty  Jewels, Clothes, and Women, are all best discerned by the Light of the Sun.     \n",
       "251                                                                                                                                                                                                                                                                                                                                  You know the Story of  Cydippe  45 , who was outwitted by a Letter inclosed in an Apple  by which Means she was made to speak Words she never intended.     \n",
       "391  Lieutenant-General  Achilles , who was to command a large Body of Grenadiers, which the  Greeks  call  Myrmidons , did not behave handsomely on that Occasion, though he got off afterwards at a Court-Martial by pleading, that his Mother  who had a great deal in her own Power  had insisted on his acting the Part he did  for, I am ashamed to say, he dressed himself in Women's Clothes, and hid himself at the House of one  Lycomedes , a Man of good Fortune in those parts.     \n",
       "358                                                                                                                                                                                                                                                                                                                                                                                                                          Note D  This is the most exceptionable Passage in the whole Work.   \n",
       "403                                                                                                                                                                                                                                                                                                                                                                                                                                                    Is this the Ravisher you are afraid of?   \n",
       "\n",
       "                                            actual_quotes  similarity_score  \n",
       "38   My hopes are not always realized, but I always hope.          0.418546  \n",
       "261  My hopes are not always realized, but I always hope.          0.600984  \n",
       "140  My hopes are not always realized, but I always hope.          0.615831  \n",
       "381  My hopes are not always realized, but I always hope.          0.808868  \n",
       "207  My hopes are not always realized, but I always hope.          0.872575  \n",
       "123  My hopes are not always realized, but I always hope.          0.423778  \n",
       "251  My hopes are not always realized, but I always hope.          0.515506  \n",
       "391  My hopes are not always realized, but I always hope.          0.612865  \n",
       "358  My hopes are not always realized, but I always hope.          0.374975  \n",
       "403  My hopes are not always realized, but I always hope.          0.640300  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/gdppvj912kv3ds7_xnf0q_fc0000gn/T/ipykernel_36937/2330900647.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity_score = doc_generated.similarity(doc_actual)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Let the man who does not wish to be idle fall in love!',\n",
       " 'To love and be loved is to feel the sun from both sides.',\n",
       " \"Love yields to business. If you seek a way out of love, be busy; you'll be safe then.\",\n",
       " 'Happy is the man who has broken the chains which hurt the mind, and has given up worrying once and for all.',\n",
       " 'Nothing is stronger than habit.',\n",
       " 'Dripping water hollows out stone, not through force but through persistence.',\n",
       " 'It is no use to blame the looking glass if your face is awry.',\n",
       " 'Resist beginnings; the remedy comes too late when the disease has gained strength by long delays.',\n",
       " 'The mind, conscious of rectitude, laughed to scorn the falsehood of report.',\n",
       " 'The cause is hidden. The effect is visible to all.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################\n",
    "# POC: To see if generate a response based on a quote\n",
    "# Situation: There is a general tweet\n",
    "# Task: Generate a list of candidate quotes\n",
    "# Action: Create a model that assigns a score to each quote\n",
    "# Result: The top 1 quote is returned\n",
    "##################################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "DATA_DIR = \"./../data\"\n",
    "files = [\n",
    "    \"RemediaAmoris.txt\",\n",
    "    \"Heroides.txt\",\n",
    "    \"Amours.txt\",\n",
    "    \"Fasti.txt\",\n",
    "    \"MetamorphosesI_VII.txt\",\n",
    "    \"MetamorphosesVIII_XV.txt\",\n",
    "    \"MetamorphosesofPublius.txt\",\n",
    "    \"LoversAssistant.txt\",\n",
    "    \"LastPoems.txt\",\n",
    "]\n",
    "docs = [f\"{DATA_DIR}/{file}\" for file in files]\n",
    "documents = SimpleDirectoryReader(input_files=docs).load_data()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=25)\n",
    "texts = text_splitter.create_documents(docs)\n",
    "directory = \"index_store\"\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local(\"index_store\", OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_interface = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "response = qa_interface(\n",
    "    f\"\"\"\n",
    "I am a big fan of ovid. \n",
    "Please recommend 10 memorable quotes to me along with the source document they were taken from.\n",
    "\n",
    "Do NOT include quotes I already have:\n",
    "{df[\"Quote\"].tolist()}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authorship authentication\n",
    "\n",
    "**[Who Wrote it and Why?\n",
    "Prompting Large-Language Models for Authorship Verification](https://arxiv.org/pdf/2310.08123.pdf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Authorship Attribution\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "\n",
    "template = f\"\"\"Task: On a scale of 0 to 1, with 0 indicating low confidence\n",
    "and 1 indicating high confidence, please provide a general\n",
    "assessment of the likelihood that given text \n",
    "written by the same author as the provided reference. Your answer should reflect a\n",
    "moderate level of strictness in scoring. Here are some\n",
    "relevant variables to this problem.\n",
    "1. punctuation style(e.g. hyphen, brackets, colon, comma,\n",
    "parenthesis, quotation mark)\n",
    "2. special characters style, capitalization style(e.g.\n",
    "Continuous capitalization, capitalizing certain words)\n",
    "3. acronyms and abbreviations(e.g. Usage of acronyms\n",
    "such as OMG, Abbreviations without punctuation marks\n",
    "such as Mr Rochester vs. Mr. Rochester,Unusual\n",
    "abbreviations such as def vs. definitely)\n",
    "4. writing style\n",
    "5. expressions and Idioms\n",
    "6. tone and mood\n",
    "7. sentence structure\n",
    "8. any other relevant aspect\n",
    "First step: Understand the problem, extracting relevant\n",
    "variables and devise a plan to solve the problem. Then,\n",
    "carry out the plan and solve the problem step by step.\n",
    "9. One (or both) of the texts is written by the famous Latin author \"Ovid\"\n",
    "Finally, show the confidence score.\n",
    "\n",
    "The following are all quotes by Ovid for reference:\n",
    "'Love is a thing full of anxious fears.',\n",
    " 'Now are fields of corn where Troy once stood.',\n",
    " \"We're slow to believe what wounds us.\",\n",
    " \"The end proves the acts (were done), or the result is a test of the actions; Ovid's line 85 full translation: “The event proves well the wisdom of her [Phyllis'] course.”\",\n",
    " \"Let him who loves, where love success may find, Spread all his sails before the prosp'rous wind.\",\n",
    " 'Resist beginnings; the remedy comes too late when the disease has gained strength by long delays.',\n",
    " \"Love yields to business. If you seek a way out of love, be busy; you'll be safe then.\",\n",
    " 'The gods behold all righteous actions.',\n",
    " 'There is a god within us.',\n",
    " 'The mind, conscious of rectitude, laughed to scorn the falsehood of report.',\n",
    " 'Every lover is a soldier.',\n",
    " 'Let the man who does not wish to be idle fall in love!',\n",
    " 'Far away be that fate!',\n",
    " 'They bear punishment with equanimity who have earned it.',\n",
    " \"We take no pleasure in permitted joys. But what's forbidden is more keenly sought.\",\n",
    " 'Who is allowed to sin, sins less.' \n",
    " \n",
    " \"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ]\n",
    ")\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Quotes from LLM Authorshipp Attribution\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "input_string = response[\"result\"]\n",
    "\n",
    "\n",
    "def get_quotes(input_string):\n",
    "    \"\"\"Extract quotes from a string that has been created by an LLM string prompt.\"\"\"\n",
    "    # Extract the lines that start with a number\n",
    "    lines_with_stripped_numbers = [\n",
    "        re.sub(r\"^\\d+\\.\\s*\", \"\", line.strip())\n",
    "        for line in input_string.splitlines()\n",
    "        if re.match(r\"^\\d+\\.\", line)\n",
    "    ]\n",
    "\n",
    "    # Print the extracted lines\n",
    "    quotes = []\n",
    "    pattern2 = r'\"([^\"]+)\"\\s*-\\s*(.+)'\n",
    "\n",
    "    for line in lines_with_stripped_numbers:\n",
    "        match = re.search(pattern2, line)\n",
    "        q = match.group(1)\n",
    "        w = match.group(2)\n",
    "        quotes.append((q, w))\n",
    "    return quotes\n",
    "\n",
    "\n",
    "quotes = get_quotes(response[\"result\"])\n",
    "quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score New Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def score_quotes(quotes=None):\n",
    "    \"\"\"Score a list of quotes that have been generated by an LLM string prompt.\n",
    "\n",
    "    quotes example:\n",
    "    [('Dripping water hollows out stone, not through force but through persistence.',\n",
    "    'Metamorphoses'),\n",
    "\n",
    "    \"\"\"\n",
    "    if quotes is None:\n",
    "        quotes = []\n",
    "\n",
    "    # Define the regex pattern\n",
    "    pattern = r\"(\\d+\\.\\d+)\"\n",
    "\n",
    "    # Get the quote string (not the work)\n",
    "    quotes_text = [q[0] for q in quotes]\n",
    "    quotes_work = [q[1] for q in quotes]\n",
    "\n",
    "    # Extract the scores\n",
    "    scores = []\n",
    "    score_reasons = []\n",
    "    for q in quotes_text:\n",
    "        r = chain.invoke({\"text\": q})\n",
    "        r = \" \".join(r)\n",
    "        score_reasons.append(r)\n",
    "        match = re.search(pattern, r)\n",
    "        score = match[0] if match else -1\n",
    "        scores.append(score)\n",
    "    return list(zip(*(scores, score_reasons, quotes_text, quotes_work)))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "scored_quotes = score_quotes(quotes)\n",
    "scored_quotes_df = pd.DataFrame(\n",
    "    scored_quotes, columns=[\"score\", \"reason\", \"quote\", \"work\"]\n",
    ")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "scored_quotes_df  # [\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_quotes_df[\"quote\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-Based Quotation Recommendation\n",
    "\n",
    "Resource:\n",
    "* https://arxiv.org/pdf/2005.08319.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of Retrieval Accuracy\n",
    "\n",
    "The below uses current pipeline for 2 reasons:\n",
    "1) To assess the hulicination affect against current pipeline\n",
    "2) To assess scoring variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "non_ovid_generated_quotes = [\n",
    "    \"One man's meat is another man's poison.\",\n",
    "    \"Fortune favors the bold.\",\n",
    "    \"Wherever there is a human being, there is an opportunity for a kindness.\",\n",
    "    \"Love is a kind of warfare.\",\n",
    "    \"One man's meat is another man's poison.\",\n",
    "    \"To be loved, be lovable.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = r\"(\\d+\\.\\d+)\"\n",
    "\n",
    "\n",
    "scores = []\n",
    "strings = []\n",
    "for q in non_ovid_generated_quotes:\n",
    "    r = chain.invoke({\"text\": q})\n",
    "    r = \" \".join(r)\n",
    "    strings.append(r)\n",
    "    match = re.search(pattern, r)\n",
    "    score = match[0] if match else -1\n",
    "    scores.append(score)\n",
    "    print(r)\n",
    "\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"questionable_quote\": non_ovid_generated_quotes,\n",
    "        \"authorship_match_score\": scores,\n",
    "        \"is_original\": [0, 0, 0, 1, 0, 1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_quotes_df[scored_quotes_df[\"score\"].astype(float) < 0.5][\"quote\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Compare to quotes\n",
    "generated_quotes = scored_quotes_df[scored_quotes_df[\"score\"].astype(float) > 0.5][\n",
    "    \"quote\"\n",
    "].tolist()\n",
    "\n",
    "# Read in existing quotes\n",
    "df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process each quote and calculate similarity scores\n",
    "similarity_data = []\n",
    "\n",
    "for generated_quote, actual_quote in product(generated_quotes, df[\"Quote\"]):\n",
    "    # Process the quotes with spaCy\n",
    "    doc_generated = nlp(generated_quote)\n",
    "    doc_actual = nlp(actual_quote)\n",
    "\n",
    "    # Calculate similarity score\n",
    "    similarity_score = doc_generated.similarity(doc_actual)\n",
    "\n",
    "    # Append data to the list\n",
    "    similarity_data.append(\n",
    "        {\n",
    "            \"generated_quotes\": generated_quote,\n",
    "            \"actual_quotes\": actual_quote,\n",
    "            \"similarity_score\": similarity_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a DataFrame from the similarity data\n",
    "similarity_df = pd.DataFrame(similarity_data).sort_values(\n",
    "    \"similarity_score\", ascending=False\n",
    ")\n",
    "display(similarity_df.head(2))\n",
    "\n",
    "# Seems like there might be a magic number similarity score < 0.65\n",
    "print(\"unique quutes\")\n",
    "\n",
    "similiar_quotes = similarity_df[similarity_df[\"similarity_score\"] > 0.65][\n",
    "    \"generated_quotes\"\n",
    "].unique()\n",
    "\n",
    "# Filter out the similar quotes\n",
    "new_quotes = similarity_df[~similarity_df[\"generated_quotes\"].isin(similiar_quotes)][\n",
    "    \"generated_quotes\"\n",
    "].unique()\n",
    "\n",
    "# Get the works for the new quotes\n",
    "new_quote_works = []\n",
    "for q in new_quotes:\n",
    "    for quote, work in quotes:\n",
    "        if q == quote:\n",
    "            new_quote_works.append(work)\n",
    "df_new_quotes = pd.DataFrame(\n",
    "    list(zip(*(new_quotes, new_quote_works))), columns=[\"Quote\", \"Work\"]\n",
    ")\n",
    "df_new_quotes[\"Quote in Latin\"] = None\n",
    "df_new_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similiar_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"highest score comparison:\")\n",
    "idx = 54\n",
    "print(\"GENERATED:\", similarity_df.iloc[54][\"generated_quotes\"])\n",
    "print(\"ACTUAL:\", similarity_df.iloc[54][\"actual_quotes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage of Additional Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Quote in Latin</th>\n",
       "      <th>Work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love is a thing full of anxious fears.</td>\n",
       "      <td>Res est solliciti plena timoris amor.</td>\n",
       "      <td>Heroides (The Heroines), I, 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now are fields of corn where Troy once stood.</td>\n",
       "      <td>Iam seges est ubi Troia fuit.</td>\n",
       "      <td>Heroides (The Heroines), I, 53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Quote  \\\n",
       "0         Love is a thing full of anxious fears.   \n",
       "1  Now are fields of corn where Troy once stood.   \n",
       "\n",
       "                          Quote in Latin                            Work  \n",
       "0  Res est solliciti plena timoris amor.  Heroides (The Heroines), I, 12  \n",
       "1          Iam seges est ubi Troia fuit.  Heroides (The Heroines), I, 53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe shape: (51, 3)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read in the existing dataframe\n",
    "# df = pd.read_json(\"./../app/ovid_quotes.json\")\n",
    "\n",
    "# # Manually append a new row to the dataframe\n",
    "# new_row = {\n",
    "#     \"Quote\": \"Greet them (others) by their names it costs you nothing.\",\n",
    "#     \"Work\": \"Ars Amatoria\",\n",
    "#     \"Quote in Latin\": \"\",\n",
    "# }\n",
    "# df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# # Print the updated dataframe\n",
    "# display(df.head(2))\n",
    "# df.to_json(\"./../app/ovid_quotes.json\")\n",
    "# print(\"New dataframe shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After quotes works have passed the assessment bars above\n",
    "df = pd.concat([df, df_new_quotes]).reset_index(drop=True)\n",
    "df.to_json(\"./../ovid_quotes.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmoresV2.pdf\n",
      "AmoresV2.txt\n",
      "Amours.txt\n",
      "Fasti.txt\n",
      "FastiV2.pdf\n",
      "FastiV2.txt\n",
      "Heroides.pdf\n",
      "Heroides.txt\n",
      "HeroidesV2.txt\n",
      "LastPoems.txt\n",
      "LostPoemsV2.txt\n",
      "LoversAssistant.txt\n",
      "MetamorphosesI_VII.txt\n",
      "MetamorphosesV2.pdf\n",
      "MetamorphosesV2.txt\n",
      "MetamorphosesVIII_XV.txt\n",
      "MetamorphosesofPublius.txt\n",
      "RemediaAmoris.txt\n",
      "lostpoems.pdf\n",
      "notes.jsonl\n",
      "notes_validation.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  302k  100  302k    0     0   380k      0 --:--:-- --:--:-- --:--:--  381k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ../data\n",
    "curl https://web.seducoahuila.gob.mx/biblioweb/upload/THE%20ART%20OF%20LOVE.pdf > ../data/ArsAmatoria.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Initialize an empty string to store the extracted text\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        # Iterate through pages and extract text\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            extracted_text += page.get_text()\n",
    "\n",
    "        return extracted_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "pdf_file_path = \"../data/ArsAmatoria.pdf\"  # Replace with the path to your PDF file\n",
    "extracted_text = extract_text_from_pdf(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eat.',\n",
       " 'As',\n",
       " 'her',\n",
       " 'breath',\n",
       " 'returned,',\n",
       " 'she',\n",
       " 'tore',\n",
       " 'the',\n",
       " 'thin',\n",
       " 'clothing']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(extracted_text.split()))\n",
    "extracted_text.split()[-1000:-990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file created successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/ArsAmatoria.txt\"\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(extracted_text)\n",
    "\n",
    "print(\"Text file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Quote Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# import utils\n",
    "import configparser\n",
    "from pprint import pprint\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "f1 = \"./../data/LostPoemsV2.txt\"\n",
    "f2 = \"./../data/FastiV2.txt\"\n",
    "\n",
    "docs = [f1, f2]\n",
    "documents = SimpleDirectoryReader(input_files=docs).load_data()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=25)\n",
    "texts = text_splitter.create_documents(docs)\n",
    "directory = \"index_store\"\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)\n",
    "\n",
    "vector_index = FAISS.load_local(\"index_store\", OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but as an AI language model, I do not have the ability to browse specific files or access specific quotes from works of literature. I recommend reading Ovid's works, such as \"Lost Poems\" and \"Fasti,\" to discover and appreciate the memorable quotes within them.\n"
     ]
    }
   ],
   "source": [
    "qa_interface = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "response = qa_interface(\n",
    "    \"\"\"\n",
    "I am a big fan of ovid. \n",
    "Please recommend memorable quotes to me.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
